{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O4calY-IqoXt"
      },
      "source": [
        "# Monte-Carlo Off-Police"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CwJjLOm-qo5x"
      },
      "source": [
        "### Instalação de pacotes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3H7uCS7cpC0y"
      },
      "outputs": [],
      "source": [
        "from IPython.display import clear_output\n",
        "!apt-get install ffmpeg freeglut3-dev xvfb  \n",
        "!pip install gym[all]==00.25.1\n",
        "!pip install gym[atari,accept-rom-license]==00.25.1\n",
        "!pip install pyglet\n",
        "!pip install stable-baselines3[extra]\n",
        "!pip install optuna\n",
        "clear_output()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OkBUSAK5qrJa",
        "outputId": "e13fc308-c3fd-433d-e6b1-6ab10530add3"
      },
      "outputs": [],
      "source": [
        "!mkdir log_project"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Usxq5Z1qwbj"
      },
      "source": [
        "### Imports\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ala9DWUOqwsJ",
        "outputId": "ac44d2d3-a411-4024-a6e4-9869f2951f43"
      },
      "outputs": [],
      "source": [
        "import gym\n",
        "import numpy as np\n",
        "import tensorboard\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "\n",
        "%load_ext tensorboard\n",
        "\n",
        "import gym\n",
        "import numpy as np\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SdZ591gXq5aK"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pLlWktrRj9GZ"
      },
      "source": [
        "### Para salvar vídeo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MPyfQxD5z26J",
        "outputId": "3ed49373-2f2d-47f6-d865-68e531bb75e3"
      },
      "outputs": [],
      "source": [
        "# Set up fake display; otherwise rendering will fail\n",
        "import os\n",
        "!pip install stable-baselines3[extra]\n",
        "os.system(\"Xvfb :1 -screen 0 1024x768x24 &\")\n",
        "os.environ['DISPLAY'] = ':1'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LTRNUfulOGaF"
      },
      "source": [
        "A gravação é feita com o wrapper [VecVideoRecorder](https://stable-baselines.readthedocs.io/en/master/guide/vec_envs.html#vecvideorecorder)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_24l7Zn3P9mH"
      },
      "outputs": [],
      "source": [
        "from stable_baselines3.common.vec_env import VecVideoRecorder, DummyVecEnv\n",
        "\n",
        "def record_video(env_id, model, video_length=500, prefix='', video_folder='videos/'):\n",
        "  \"\"\"\n",
        "  :param env_id: (str)\n",
        "  :param model: (RL model)\n",
        "  :param video_length: (int)\n",
        "  :param prefix: (str)\n",
        "  :param video_folder: (str)\n",
        "  \"\"\"\n",
        "  eval_env = DummyVecEnv([lambda: gym.make(env_id)])\n",
        "  # Start the video at step=0 and record the given number of steps\n",
        "  eval_env = VecVideoRecorder(eval_env, video_folder=video_folder,\n",
        "                              record_video_trigger=lambda step: step == 0, video_length=video_length,\n",
        "                              name_prefix=prefix)\n",
        "\n",
        "  obs = eval_env.reset()\n",
        "  for _ in range(video_length):\n",
        "    action, _ = model.predict(obs)\n",
        "    obs, _, _, _ = eval_env.step(action)\n",
        "\n",
        "  # Close the video recorder\n",
        "  eval_env.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SLzXxO8VMD6N"
      },
      "outputs": [],
      "source": [
        "import base64\n",
        "from pathlib import Path\n",
        "\n",
        "from IPython import display as ipythondisplay\n",
        "\n",
        "def show_videos(video_path='', prefix=''):\n",
        "  \"\"\"\n",
        "  Taken from https://github.com/eleurent/highway-env\n",
        "\n",
        "  :param video_path: (str) Path to the folder containing videos\n",
        "  :param prefix: (str) Filter the video, showing only the only starting with this prefix\n",
        "  \"\"\"\n",
        "  html = []\n",
        "  for mp4 in Path(video_path).glob(\"{}*.mp4\".format(prefix)):\n",
        "      video_b64 = base64.b64encode(mp4.read_bytes())\n",
        "      html.append('''<video alt=\"{}\" autoplay \n",
        "                    loop controls style=\"height: 400px;\">\n",
        "                    <source src=\"data:video/mp4;base64,{}\" type=\"video/mp4\" />\n",
        "                </video>'''.format(mp4, video_b64.decode('ascii')))\n",
        "  ipythondisplay.display(ipythondisplay.HTML(data=\"<br>\".join(html)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4eFhFiESi4Y7"
      },
      "outputs": [],
      "source": [
        "# ideias adaptadas de : https://www.anyscale.com/blog/an-introduction-to-reinforcement-learning-with-openai-gym-rllib-and-google\n",
        "from base64 import b64encode\n",
        "from IPython.display import HTML\n",
        "from gym.wrappers.monitoring.video_recorder import VideoRecorder\n",
        "\n",
        "def render_mp4(videopath: str) -> str:\n",
        "  \"\"\"\n",
        "  Gets a string containing a b4-encoded version of the MP4 video\n",
        "  at the specified path.\n",
        "  \"\"\"\n",
        "  mp4 = open(videopath, 'rb').read()\n",
        "  base64_encoded_mp4 = b64encode(mp4).decode()\n",
        "  html_code = f'<video width=400 controls><source src=\"data:video/mp4;' \\\n",
        "         f'base64,{base64_encoded_mp4}\" type=\"video/mp4\"></video>'\n",
        "  return HTML(html_code)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bHTzWX3krgKW"
      },
      "source": [
        "# Código"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vU1HhpkMrJUX"
      },
      "outputs": [],
      "source": [
        "ENV_NAME = \"Taxi-v3\"  \n",
        " \n",
        "env = gym.make(ENV_NAME)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PGDXptJdP9mM"
      },
      "source": [
        "## Off-policy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Off-Policy Padrão"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0B2H4gpClZq0"
      },
      "outputs": [],
      "source": [
        "def choose_action(Q, state):\n",
        "    return np.argmax(Q[state])\n",
        "\n",
        "def choose_actionB(num_actions):\n",
        "    return np.random.randint(0, num_actions)\n",
        "\n",
        "# Algoritmo Monte-Carlo de Controle, variante \"toda-visita\".\n",
        "# Atenção: os espaços de estados e de ações precisam ser discretos, dados por valores inteiros\n",
        "def run_montecarloOffP(env, episodes, gamma=0.95, epsilon=0.1, render=False):\n",
        "    assert isinstance(env.observation_space, gym.spaces.Discrete)\n",
        "    assert isinstance(env.action_space, gym.spaces.Discrete)\n",
        "    \n",
        "    num_actions = env.action_space.n\n",
        "    \n",
        "    # inicializa a tabela Q toda com zero,\n",
        "    # usar o estado como índice das linhas e a ação como índice das colunas\n",
        "    Q = np.zeros(shape = (env.observation_space.n, num_actions))\n",
        "    C = np.zeros(shape = (env.observation_space.n, num_actions))\n",
        "\n",
        "    # para cada episódio, guarda sua soma de recompensas (retorno não-discontado)\n",
        "    sum_rewards_per_ep = []\n",
        "\n",
        "    # loop principal\n",
        "    for i in range(episodes):\n",
        "        done = False\n",
        "        sum_rewards, reward = 0, 0\n",
        "        ep_trajectory = []\n",
        "        \n",
        "        state = env.reset()\n",
        "    \n",
        "        # PARTE 1: executa um episódio completo\n",
        "        while done != True:   \n",
        "            # exibe/renderiza os passos no ambiente, durante 1 episódio a cada mil e também nos últimos 5 episódios \n",
        "            if render and (i >= (episodes - 5) or (i+1) % 1000 == 0):\n",
        "                env.render()\n",
        "                \n",
        "            # escolhe a próxima ação -- usa epsilon-greedy\n",
        "            action = choose_action(Q, state)\n",
        "        \n",
        "            # realiza a ação, ou seja, dá um passo no ambiente\n",
        "            next_state, reward, done, _ = env.step(action)\n",
        "            \n",
        "            # adiciona a tripla que representa este passo\n",
        "            ep_trajectory.append( (state, action, reward) )\n",
        "            \n",
        "            sum_rewards += reward\n",
        "            state = next_state\n",
        "        \n",
        "        sum_rewards_per_ep.append(sum_rewards)\n",
        "\n",
        "        # a cada 100 episódios, imprime informação sobre o progresso \n",
        "        if (i+1) % 100 == 0:\n",
        "            avg_reward = np.mean(sum_rewards_per_ep[-100:])\n",
        "            print(f\"Episode {i+1} Average Reward (last 100): {avg_reward:.3f}\")\n",
        "\n",
        "        # PARTE 2: atualiza Q (e a política, implicitamente)\n",
        "        Gt = 0\n",
        "        W = 1\n",
        "        for (s, a, r) in reversed(ep_trajectory):\n",
        "            Gt = r + gamma*Gt\n",
        "            C[s,a] = C[s,a] + W\n",
        "            delta = W * (Gt - Q[s,a])\n",
        "            Q[s,a] = Q[s,a] + (1/C[s,a])* delta\n",
        "            best = choose_action(Q,s)\n",
        "            if best != choose_actionB(num_actions): break\n",
        "            W = W*(1/(1/num_actions))\n",
        "\n",
        "    return sum_rewards_per_ep, Q\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Off-policy com weighted importance sampling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Algoritmo Monte-Carlo de Controle, variante \"toda-visita\".\n",
        "# Atenção: os espaços de estados e de ações precisam ser discretos, dados por valores inteiros\n",
        "def run_montecarloOffP_weighted(env, episodes, gamma=0.95, epsilon=0.1, render=False):\n",
        "    assert isinstance(env.observation_space, gym.spaces.Discrete)\n",
        "    assert isinstance(env.action_space, gym.spaces.Discrete)\n",
        "    \n",
        "    num_actions = env.action_space.n\n",
        "    \n",
        "    # inicializa a tabela Q toda com zero,\n",
        "    # usar o estado como índice das linhas e a ação como índice das colunas\n",
        "    Q = np.zeros(shape = (env.observation_space.n, num_actions))\n",
        "    C = np.zeros(shape = (env.observation_space.n, num_actions))\n",
        "\n",
        "    # para cada episódio, guarda sua soma de recompensas (retorno não-discontado)\n",
        "    sum_rewards_per_ep = []\n",
        "\n",
        "    # loop principal\n",
        "    for i in range(episodes):\n",
        "        done = False\n",
        "        sum_rewards, reward = 0, 0\n",
        "        ep_trajectory = []\n",
        "        \n",
        "        state = env.reset()\n",
        "    \n",
        "        # PARTE 1: executa um episódio completo\n",
        "        while done != True:   \n",
        "            # exibe/renderiza os passos no ambiente, durante 1 episódio a cada mil e também nos últimos 5 episódios \n",
        "            if render and (i >= (episodes - 5) or (i+1) % 1000 == 0):\n",
        "                env.render()\n",
        "                \n",
        "            # escolhe a próxima ação -- usa epsilon-greedy\n",
        "            action = choose_action(Q, state)\n",
        "        \n",
        "            # realiza a ação, ou seja, dá um passo no ambiente\n",
        "            next_state, reward, done, _ = env.step(action)\n",
        "            \n",
        "            # adiciona a tripla que representa este passo\n",
        "            ep_trajectory.append( (state, action, reward) )\n",
        "            \n",
        "            sum_rewards += reward\n",
        "            state = next_state\n",
        "        \n",
        "        sum_rewards_per_ep.append(sum_rewards)\n",
        "\n",
        "        # a cada 100 episódios, imprime informação sobre o progresso \n",
        "        if (i+1) % 100 == 0:\n",
        "            avg_reward = np.mean(sum_rewards_per_ep[-100:])\n",
        "            print(f\"Episode {i+1} Average Reward (last 100): {avg_reward:.3f}\")\n",
        "\n",
        "        # PARTE 2: atualiza Q (e a política, implicitamente)\n",
        "        Gt = 0\n",
        "        W = 1\n",
        "        gamma_fact = 1\n",
        "        for (i, (s, a, r)) in enumerate(reversed(ep_trajectory)):\n",
        "            Gt = Gt + r\n",
        "            if i == 1 and gamma != 1:\n",
        "                gamma_fact *= (1-gamma)/gamma\n",
        "            else:\n",
        "                gamma_fact *= gamma\n",
        "            actual_w = W * gamma_fact\n",
        "            C[s,a] = C[s,a] + actual_w\n",
        "            delta = actual_w * (Gt - Q[s,a])\n",
        "            Q[s,a] = Q[s,a] + (1/C[s,a])* delta\n",
        "            best = choose_action(Q,s)\n",
        "            W = W*(1/(1/num_actions))\n",
        "            if best != choose_actionB(num_actions): break\n",
        "\n",
        "    return sum_rewards_per_ep, Q"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gg2yPwHrP9mN"
      },
      "source": [
        "## On-Policy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yXaGrkX_P9mN"
      },
      "outputs": [],
      "source": [
        "# Esta é a política. Neste caso, escolhe uma ação com base nos valores\n",
        "# da tabela Q, usando uma estratégia epsilon-greedy.\n",
        "def pi_policy(Q, state, num_actions, epsilon):\n",
        "    if np.random.random() < epsilon:\n",
        "        return np.random.randint(0, num_actions)\n",
        "    else:\n",
        "        return np.argmax(Q[state])\n",
        "\n",
        "\n",
        "# Algoritmo Monte-Carlo de Controle, variante \"toda-visita\".\n",
        "# Atenção: os espaços de estados e de ações precisam ser discretos, dados por valores inteiros\n",
        "def run_montecarloOnP(env, episodes, lr=0.1, gamma=0.95, epsilon=0.1, render=False):\n",
        "    assert isinstance(env.observation_space, gym.spaces.Discrete)\n",
        "    assert isinstance(env.action_space, gym.spaces.Discrete)\n",
        "    \n",
        "    num_actions = env.action_space.n\n",
        "    \n",
        "    # inicializa a tabela Q toda com zero,\n",
        "    # usar o estado como índice das linhas e a ação como índice das colunas\n",
        "    Q = np.zeros(shape = (env.observation_space.n, num_actions))\n",
        "\n",
        "    # para cada episódio, guarda sua soma de recompensas (retorno não-discontado)\n",
        "    sum_rewards_per_ep = []\n",
        "\n",
        "    # loop principal\n",
        "    for i in range(episodes):\n",
        "        done = False\n",
        "        sum_rewards, reward = 0, 0\n",
        "        ep_trajectory = []\n",
        "        \n",
        "        state = env.reset()\n",
        "    \n",
        "        # PARTE 1: executa um episódio completo\n",
        "        while done != True:   \n",
        "            # exibe/renderiza os passos no ambiente, durante 1 episódio a cada mil e também nos últimos 5 episódios \n",
        "            if render and (i >= (episodes - 5) or (i+1) % 1000 == 0):\n",
        "                env.render()\n",
        "                \n",
        "            # escolhe a próxima ação -- usa epsilon-greedy\n",
        "            action = pi_policy(Q, state, num_actions, epsilon)\n",
        "        \n",
        "            # realiza a ação, ou seja, dá um passo no ambiente\n",
        "            next_state, reward, done, _ = env.step(action)\n",
        "            \n",
        "            # adiciona a tripla que representa este passo\n",
        "            ep_trajectory.append( (state, action, reward) )\n",
        "            \n",
        "            sum_rewards += reward\n",
        "            state = next_state\n",
        "        \n",
        "        sum_rewards_per_ep.append(sum_rewards)\n",
        "\n",
        "        # a cada 100 episódios, imprime informação sobre o progresso \n",
        "        if (i+1) % 100 == 0:\n",
        "            avg_reward = np.mean(sum_rewards_per_ep[-100:])\n",
        "            print(f\"Episode {i+1} Average Reward (last 100): {avg_reward:.3f}\")\n",
        "\n",
        "        # PARTE 2: atualiza Q (e a política, implicitamente)\n",
        "        Gt = 0\n",
        "        for (s, a, r) in reversed(ep_trajectory):\n",
        "            Gt = r + gamma*Gt\n",
        "            delta = Gt - Q[s,a]\n",
        "            Q[s,a] = Q[s,a] + lr * delta\n",
        "\n",
        "    return sum_rewards_per_ep, Q"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TwSugu33P9mO"
      },
      "source": [
        "### Execução Off-Policy Padrão"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Au89jJmZTJFA"
      },
      "source": [
        "#### Otimiza Parâmetros"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bhgOjTT3_xfv"
      },
      "outputs": [],
      "source": [
        "from numpy.random.mtrand import gamma\n",
        "\n",
        "import optuna\n",
        "\n",
        "\n",
        "\n",
        "ENV = gym.make(\"Taxi-v3\")\n",
        "\n",
        "\n",
        "# Esta função faz um treinamento com o Expected-SARSA, usando parâmetros sugeridos pelo Optuna.\n",
        "# Retorna a média dos retornos dos últimos 100 episódios.\n",
        "def train_values(trial : optuna.Trial):\n",
        "    \n",
        "    # chama os métodos do \"trial\" (tentativa) para sugerir valores para os parâmetros\n",
        "    gamma = trial.suggest_uniform('gamma', 0.02, 1.0)\n",
        "    eps = trial.suggest_uniform('epsilon', 0.01, 0.2)\n",
        "    #bins1 = trial.suggest_int('bins1', 5, 100)\n",
        "    #bins2 = trial.suggest_int('bins2', 5, 100)\n",
        "    \n",
        "    print(f\"\\nTRIAL #{trial.number}: eps={eps}, gamma={gamma}\")\n",
        "\n",
        "    # roda o algoritmo e recebe os retornos não-descontados\n",
        "    #env_wrapper = DiscreteObservationWrapper(ENV, [bins1,bins2])\n",
        "    (returns, _) = run_montecarloOffP(env, 20000, gamma, eps, render=False)\n",
        "    return sum(returns[-100:])/100 "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ehjw4UTFA40G",
        "outputId": "b9c4cc5a-30fb-4aa8-94b1-a256ad3c5d20"
      },
      "outputs": [],
      "source": [
        "study = optuna.create_study(direction='maximize', \n",
        "                            storage='sqlite:///optuna_studies.db', \n",
        "                            study_name= 'new_MC_offpolice', \n",
        "                            load_if_exists=True)\n",
        "study.optimize(train_values, n_trials=20) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kZEkS9SyTQxP"
      },
      "source": [
        "#### Execução"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7I9paaU_CbTh"
      },
      "outputs": [],
      "source": [
        "\n",
        "env = gym.make(\"Taxi-v3\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3e3Mc8g9pnRE",
        "outputId": "e2f1e190-4735-4911-b7a3-9cb1c257817a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Episode 100 Average Reward (last 100): -200.000\n",
            "Episode 200 Average Reward (last 100): -342.470\n",
            "Episode 300 Average Reward (last 100): -643.610\n",
            "Episode 400 Average Reward (last 100): -589.880\n",
            "Episode 500 Average Reward (last 100): -571.700\n",
            "Episode 600 Average Reward (last 100): -377.030\n",
            "Episode 700 Average Reward (last 100): -568.460\n",
            "Episode 800 Average Reward (last 100): -431.840\n",
            "Episode 900 Average Reward (last 100): -483.590\n",
            "Episode 1000 Average Reward (last 100): -428.780\n",
            "Episode 1100 Average Reward (last 100): -289.190\n",
            "Episode 1200 Average Reward (last 100): -518.330\n",
            "Episode 1300 Average Reward (last 100): -357.950\n",
            "Episode 1400 Average Reward (last 100): -287.390\n",
            "Episode 1500 Average Reward (last 100): -270.920\n",
            "Episode 1600 Average Reward (last 100): -429.050\n",
            "Episode 1700 Average Reward (last 100): -323.480\n",
            "Episode 1800 Average Reward (last 100): -339.770\n",
            "Episode 1900 Average Reward (last 100): -305.300\n",
            "Episode 2000 Average Reward (last 100): -340.040\n",
            "Episode 2100 Average Reward (last 100): -338.960\n",
            "Episode 2200 Average Reward (last 100): -304.220\n",
            "Episode 2300 Average Reward (last 100): -304.940\n",
            "Episode 2400 Average Reward (last 100): -252.920\n",
            "Episode 2500 Average Reward (last 100): -270.830\n",
            "Episode 2600 Average Reward (last 100): -375.410\n",
            "Episode 2700 Average Reward (last 100): -355.520\n",
            "Episode 2800 Average Reward (last 100): -253.370\n",
            "Episode 2900 Average Reward (last 100): -341.570\n",
            "Episode 3000 Average Reward (last 100): -253.280\n",
            "Episode 3100 Average Reward (last 100): -323.480\n",
            "Episode 3200 Average Reward (last 100): -288.290\n",
            "Episode 3300 Average Reward (last 100): -217.640\n",
            "Episode 3400 Average Reward (last 100): -302.960\n",
            "Episode 3500 Average Reward (last 100): -304.040\n",
            "Episode 3600 Average Reward (last 100): -200.000\n",
            "Episode 3700 Average Reward (last 100): -287.930\n",
            "Episode 3800 Average Reward (last 100): -253.100\n",
            "Episode 3900 Average Reward (last 100): -287.210\n",
            "Episode 4000 Average Reward (last 100): -234.830\n",
            "Episode 4100 Average Reward (last 100): -270.650\n",
            "Episode 4200 Average Reward (last 100): -253.010\n",
            "Episode 4300 Average Reward (last 100): -324.740\n",
            "Episode 4400 Average Reward (last 100): -307.190\n",
            "Episode 4500 Average Reward (last 100): -307.460\n",
            "Episode 4600 Average Reward (last 100): -271.640\n",
            "Episode 4700 Average Reward (last 100): -235.640\n",
            "Episode 4800 Average Reward (last 100): -269.930\n",
            "Episode 4900 Average Reward (last 100): -200.000\n",
            "Episode 5000 Average Reward (last 100): -200.000\n",
            "Episode 5100 Average Reward (last 100): -234.380\n",
            "Episode 5200 Average Reward (last 100): -253.100\n",
            "Episode 5300 Average Reward (last 100): -200.000\n",
            "Episode 5400 Average Reward (last 100): -200.000\n",
            "Episode 5500 Average Reward (last 100): -235.550\n",
            "Episode 5600 Average Reward (last 100): -200.000\n",
            "Episode 5700 Average Reward (last 100): -235.550\n",
            "Episode 5800 Average Reward (last 100): -268.760\n",
            "Episode 5900 Average Reward (last 100): -341.120\n",
            "Episode 6000 Average Reward (last 100): -235.190\n",
            "Episode 6100 Average Reward (last 100): -234.200\n",
            "Episode 6200 Average Reward (last 100): -287.480\n",
            "Episode 6300 Average Reward (last 100): -288.290\n",
            "Episode 6400 Average Reward (last 100): -253.100\n",
            "Episode 6500 Average Reward (last 100): -200.000\n",
            "Episode 6600 Average Reward (last 100): -235.370\n",
            "Episode 6700 Average Reward (last 100): -235.640\n",
            "Episode 6800 Average Reward (last 100): -217.910\n",
            "Episode 6900 Average Reward (last 100): -200.000\n",
            "Episode 7000 Average Reward (last 100): -270.470\n",
            "Episode 7100 Average Reward (last 100): -200.000\n",
            "Episode 7200 Average Reward (last 100): -235.190\n",
            "Episode 7300 Average Reward (last 100): -270.830\n",
            "Episode 7400 Average Reward (last 100): -235.280\n",
            "Episode 7500 Average Reward (last 100): -200.000\n",
            "Episode 7600 Average Reward (last 100): -271.190\n",
            "Episode 7700 Average Reward (last 100): -235.190\n",
            "Episode 7800 Average Reward (last 100): -200.000\n",
            "Episode 7900 Average Reward (last 100): -233.840\n",
            "Episode 8000 Average Reward (last 100): -200.000\n",
            "Episode 8100 Average Reward (last 100): -200.000\n",
            "Episode 8200 Average Reward (last 100): -217.100\n",
            "Episode 8300 Average Reward (last 100): -253.370\n",
            "Episode 8400 Average Reward (last 100): -235.010\n",
            "Episode 8500 Average Reward (last 100): -200.000\n",
            "Episode 8600 Average Reward (last 100): -200.000\n",
            "Episode 8700 Average Reward (last 100): -200.000\n",
            "Episode 8800 Average Reward (last 100): -200.000\n",
            "Episode 8900 Average Reward (last 100): -217.820\n",
            "Episode 9000 Average Reward (last 100): -217.550\n",
            "Episode 9100 Average Reward (last 100): -235.370\n",
            "Episode 9200 Average Reward (last 100): -235.460\n",
            "Episode 9300 Average Reward (last 100): -200.000\n",
            "Episode 9400 Average Reward (last 100): -200.000\n",
            "Episode 9500 Average Reward (last 100): -200.000\n",
            "Episode 9600 Average Reward (last 100): -200.000\n",
            "Episode 9700 Average Reward (last 100): -218.000\n",
            "Episode 9800 Average Reward (last 100): -200.000\n",
            "Episode 9900 Average Reward (last 100): -200.000\n",
            "Episode 10000 Average Reward (last 100): -200.000\n",
            "Episode 10100 Average Reward (last 100): -218.000\n",
            "Episode 10200 Average Reward (last 100): -200.000\n",
            "Episode 10300 Average Reward (last 100): -200.000\n",
            "Episode 10400 Average Reward (last 100): -200.000\n",
            "Episode 10500 Average Reward (last 100): -200.000\n",
            "Episode 10600 Average Reward (last 100): -200.000\n",
            "Episode 10700 Average Reward (last 100): -200.000\n",
            "Episode 10800 Average Reward (last 100): -200.000\n",
            "Episode 10900 Average Reward (last 100): -200.000\n",
            "Episode 11000 Average Reward (last 100): -200.000\n",
            "Episode 11100 Average Reward (last 100): -200.000\n",
            "Episode 11200 Average Reward (last 100): -200.000\n",
            "Episode 11300 Average Reward (last 100): -200.000\n",
            "Episode 11400 Average Reward (last 100): -200.000\n",
            "Episode 11500 Average Reward (last 100): -217.010\n",
            "Episode 11600 Average Reward (last 100): -216.920\n",
            "Episode 11700 Average Reward (last 100): -267.680\n",
            "Episode 11800 Average Reward (last 100): -200.000\n",
            "Episode 11900 Average Reward (last 100): -200.000\n",
            "Episode 12000 Average Reward (last 100): -234.920\n",
            "Episode 12100 Average Reward (last 100): -234.920\n",
            "Episode 12200 Average Reward (last 100): -200.000\n",
            "Episode 12300 Average Reward (last 100): -200.000\n",
            "Episode 12400 Average Reward (last 100): -200.000\n",
            "Episode 12500 Average Reward (last 100): -200.000\n",
            "Episode 12600 Average Reward (last 100): -200.000\n",
            "Episode 12700 Average Reward (last 100): -200.000\n",
            "Episode 12800 Average Reward (last 100): -200.000\n",
            "Episode 12900 Average Reward (last 100): -200.000\n",
            "Episode 13000 Average Reward (last 100): -218.000\n",
            "Episode 13100 Average Reward (last 100): -217.190\n",
            "Episode 13200 Average Reward (last 100): -200.000\n",
            "Episode 13300 Average Reward (last 100): -200.000\n",
            "Episode 13400 Average Reward (last 100): -200.000\n",
            "Episode 13500 Average Reward (last 100): -200.000\n",
            "Episode 13600 Average Reward (last 100): -200.000\n",
            "Episode 13700 Average Reward (last 100): -200.000\n",
            "Episode 13800 Average Reward (last 100): -200.000\n",
            "Episode 13900 Average Reward (last 100): -200.000\n",
            "Episode 14000 Average Reward (last 100): -200.000\n",
            "Episode 14100 Average Reward (last 100): -200.000\n",
            "Episode 14200 Average Reward (last 100): -234.830\n",
            "Episode 14300 Average Reward (last 100): -200.000\n",
            "Episode 14400 Average Reward (last 100): -200.000\n",
            "Episode 14500 Average Reward (last 100): -217.910\n",
            "Episode 14600 Average Reward (last 100): -217.820\n",
            "Episode 14700 Average Reward (last 100): -200.000\n",
            "Episode 14800 Average Reward (last 100): -200.000\n",
            "Episode 14900 Average Reward (last 100): -200.000\n",
            "Episode 15000 Average Reward (last 100): -200.000\n",
            "Episode 15100 Average Reward (last 100): -200.000\n",
            "Episode 15200 Average Reward (last 100): -200.000\n",
            "Episode 15300 Average Reward (last 100): -200.000\n",
            "Episode 15400 Average Reward (last 100): -200.000\n",
            "Episode 15500 Average Reward (last 100): -200.000\n",
            "Episode 15600 Average Reward (last 100): -200.000\n",
            "Episode 15700 Average Reward (last 100): -200.000\n",
            "Episode 15800 Average Reward (last 100): -200.000\n",
            "Episode 15900 Average Reward (last 100): -200.000\n",
            "Episode 16000 Average Reward (last 100): -200.000\n",
            "Episode 16100 Average Reward (last 100): -200.000\n",
            "Episode 16200 Average Reward (last 100): -200.000\n",
            "Episode 16300 Average Reward (last 100): -200.000\n",
            "Episode 16400 Average Reward (last 100): -200.000\n",
            "Episode 16500 Average Reward (last 100): -200.000\n",
            "Episode 16600 Average Reward (last 100): -200.000\n",
            "Episode 16700 Average Reward (last 100): -200.000\n",
            "Episode 16800 Average Reward (last 100): -200.000\n",
            "Episode 16900 Average Reward (last 100): -200.000\n",
            "Episode 17000 Average Reward (last 100): -200.000\n",
            "Episode 17100 Average Reward (last 100): -218.000\n",
            "Episode 17200 Average Reward (last 100): -200.000\n",
            "Episode 17300 Average Reward (last 100): -235.370\n",
            "Episode 17400 Average Reward (last 100): -218.000\n",
            "Episode 17500 Average Reward (last 100): -200.000\n",
            "Episode 17600 Average Reward (last 100): -200.000\n",
            "Episode 17700 Average Reward (last 100): -271.640\n",
            "Episode 17800 Average Reward (last 100): -235.910\n",
            "Episode 17900 Average Reward (last 100): -200.000\n",
            "Episode 18000 Average Reward (last 100): -200.000\n",
            "Episode 18100 Average Reward (last 100): -200.000\n",
            "Episode 18200 Average Reward (last 100): -200.000\n",
            "Episode 18300 Average Reward (last 100): -200.000\n",
            "Episode 18400 Average Reward (last 100): -200.000\n",
            "Episode 18500 Average Reward (last 100): -200.000\n",
            "Episode 18600 Average Reward (last 100): -200.000\n",
            "Episode 18700 Average Reward (last 100): -200.000\n",
            "Episode 18800 Average Reward (last 100): -200.000\n",
            "Episode 18900 Average Reward (last 100): -200.000\n",
            "Episode 19000 Average Reward (last 100): -200.000\n",
            "Episode 19100 Average Reward (last 100): -200.000\n",
            "Episode 19200 Average Reward (last 100): -234.650\n",
            "Episode 19300 Average Reward (last 100): -200.000\n",
            "Episode 19400 Average Reward (last 100): -235.280\n",
            "Episode 19500 Average Reward (last 100): -200.000\n",
            "Episode 19600 Average Reward (last 100): -200.000\n",
            "Episode 19700 Average Reward (last 100): -200.000\n",
            "Episode 19800 Average Reward (last 100): -200.000\n",
            "Episode 19900 Average Reward (last 100): -200.000\n",
            "Episode 20000 Average Reward (last 100): -200.000\n",
            "Episode 20100 Average Reward (last 100): -200.000\n",
            "Episode 20200 Average Reward (last 100): -200.000\n",
            "Episode 20300 Average Reward (last 100): -200.000\n",
            "Episode 20400 Average Reward (last 100): -200.000\n",
            "Episode 20500 Average Reward (last 100): -200.000\n",
            "Episode 20600 Average Reward (last 100): -200.000\n",
            "Episode 20700 Average Reward (last 100): -270.830\n",
            "Episode 20800 Average Reward (last 100): -200.000\n",
            "Episode 20900 Average Reward (last 100): -200.000\n",
            "Episode 21000 Average Reward (last 100): -200.000\n",
            "Episode 21100 Average Reward (last 100): -200.000\n",
            "Episode 21200 Average Reward (last 100): -200.000\n",
            "Episode 21300 Average Reward (last 100): -200.000\n",
            "Episode 21400 Average Reward (last 100): -200.000\n",
            "Episode 21500 Average Reward (last 100): -270.650\n",
            "Episode 21600 Average Reward (last 100): -234.920\n",
            "Episode 21700 Average Reward (last 100): -200.000\n",
            "Episode 21800 Average Reward (last 100): -235.550\n",
            "Episode 21900 Average Reward (last 100): -253.010\n",
            "Episode 22000 Average Reward (last 100): -218.000\n",
            "Episode 22100 Average Reward (last 100): -200.000\n",
            "Episode 22200 Average Reward (last 100): -200.000\n",
            "Episode 22300 Average Reward (last 100): -200.000\n",
            "Episode 22400 Average Reward (last 100): -200.000\n",
            "Episode 22500 Average Reward (last 100): -200.000\n",
            "Episode 22600 Average Reward (last 100): -200.000\n",
            "Episode 22700 Average Reward (last 100): -200.000\n",
            "Episode 22800 Average Reward (last 100): -200.000\n",
            "Episode 22900 Average Reward (last 100): -200.000\n",
            "Episode 23000 Average Reward (last 100): -200.000\n",
            "Episode 23100 Average Reward (last 100): -200.000\n",
            "Episode 23200 Average Reward (last 100): -200.000\n",
            "Episode 23300 Average Reward (last 100): -217.550\n",
            "Episode 23400 Average Reward (last 100): -253.100\n",
            "Episode 23500 Average Reward (last 100): -200.000\n",
            "Episode 23600 Average Reward (last 100): -200.000\n",
            "Episode 23700 Average Reward (last 100): -200.000\n",
            "Episode 23800 Average Reward (last 100): -200.000\n",
            "Episode 23900 Average Reward (last 100): -200.000\n",
            "Episode 24000 Average Reward (last 100): -200.000\n",
            "Episode 24100 Average Reward (last 100): -200.000\n",
            "Episode 24200 Average Reward (last 100): -200.000\n",
            "Episode 24300 Average Reward (last 100): -200.000\n",
            "Episode 24400 Average Reward (last 100): -200.000\n",
            "Episode 24500 Average Reward (last 100): -200.000\n",
            "Episode 24600 Average Reward (last 100): -200.000\n",
            "Episode 24700 Average Reward (last 100): -200.000\n",
            "Episode 24800 Average Reward (last 100): -200.000\n",
            "Episode 24900 Average Reward (last 100): -200.000\n",
            "Episode 25000 Average Reward (last 100): -200.000\n",
            "Episode 25100 Average Reward (last 100): -200.000\n",
            "Episode 25200 Average Reward (last 100): -200.000\n",
            "Episode 25300 Average Reward (last 100): -200.000\n",
            "Episode 25400 Average Reward (last 100): -200.000\n",
            "Episode 25500 Average Reward (last 100): -200.000\n",
            "Episode 25600 Average Reward (last 100): -200.000\n",
            "Episode 25700 Average Reward (last 100): -200.000\n",
            "Episode 25800 Average Reward (last 100): -200.000\n",
            "Episode 25900 Average Reward (last 100): -200.000\n",
            "Episode 26000 Average Reward (last 100): -200.000\n",
            "Episode 26100 Average Reward (last 100): -200.000\n",
            "Episode 26200 Average Reward (last 100): -200.000\n",
            "Episode 26300 Average Reward (last 100): -200.000\n",
            "Episode 26400 Average Reward (last 100): -200.000\n",
            "Episode 26500 Average Reward (last 100): -200.000\n",
            "Episode 26600 Average Reward (last 100): -200.000\n",
            "Episode 26700 Average Reward (last 100): -200.000\n",
            "Episode 26800 Average Reward (last 100): -200.000\n",
            "Episode 26900 Average Reward (last 100): -200.000\n",
            "Episode 27000 Average Reward (last 100): -235.280\n",
            "Episode 27100 Average Reward (last 100): -217.910\n",
            "Episode 27200 Average Reward (last 100): -217.460\n",
            "Episode 27300 Average Reward (last 100): -270.380\n",
            "Episode 27400 Average Reward (last 100): -200.000\n",
            "Episode 27500 Average Reward (last 100): -200.000\n",
            "Episode 27600 Average Reward (last 100): -234.200\n",
            "Episode 27700 Average Reward (last 100): -250.400\n",
            "Episode 27800 Average Reward (last 100): -217.190\n",
            "Episode 27900 Average Reward (last 100): -234.380\n",
            "Episode 28000 Average Reward (last 100): -200.000\n",
            "Episode 28100 Average Reward (last 100): -216.740\n",
            "Episode 28200 Average Reward (last 100): -216.470\n",
            "Episode 28300 Average Reward (last 100): -200.000\n",
            "Episode 28400 Average Reward (last 100): -217.010\n",
            "Episode 28500 Average Reward (last 100): -181.650\n",
            "Episode 28600 Average Reward (last 100): -183.710\n",
            "Episode 28700 Average Reward (last 100): -173.380\n",
            "Episode 28800 Average Reward (last 100): -185.720\n",
            "Episode 28900 Average Reward (last 100): -185.590\n",
            "Episode 29000 Average Reward (last 100): -181.600\n",
            "Episode 29100 Average Reward (last 100): -183.630\n",
            "Episode 29200 Average Reward (last 100): -181.740\n",
            "Episode 29300 Average Reward (last 100): -189.760\n",
            "Episode 29400 Average Reward (last 100): -175.490\n",
            "Episode 29500 Average Reward (last 100): -187.690\n",
            "Episode 29600 Average Reward (last 100): -185.690\n",
            "Episode 29700 Average Reward (last 100): -173.430\n",
            "Episode 29800 Average Reward (last 100): -181.700\n",
            "Episode 29900 Average Reward (last 100): -181.560\n",
            "Episode 30000 Average Reward (last 100): -187.810\n",
            "Episode 30100 Average Reward (last 100): -187.670\n",
            "Episode 30200 Average Reward (last 100): -193.930\n",
            "Episode 30300 Average Reward (last 100): -177.560\n",
            "Episode 30400 Average Reward (last 100): -183.710\n",
            "Episode 30500 Average Reward (last 100): -179.550\n",
            "Episode 30600 Average Reward (last 100): -177.600\n",
            "Episode 30700 Average Reward (last 100): -187.700\n",
            "Episode 30800 Average Reward (last 100): -179.460\n",
            "Episode 30900 Average Reward (last 100): -185.800\n",
            "Episode 31000 Average Reward (last 100): -181.650\n",
            "Episode 31100 Average Reward (last 100): -187.660\n",
            "Episode 31200 Average Reward (last 100): -183.740\n",
            "Episode 31300 Average Reward (last 100): -187.840\n",
            "Episode 31400 Average Reward (last 100): -189.820\n",
            "Episode 31500 Average Reward (last 100): -177.660\n",
            "Episode 31600 Average Reward (last 100): -183.680\n",
            "Episode 31700 Average Reward (last 100): -185.690\n",
            "Episode 31800 Average Reward (last 100): -185.770\n",
            "Episode 31900 Average Reward (last 100): -193.870\n",
            "Episode 32000 Average Reward (last 100): -189.730\n",
            "Episode 32100 Average Reward (last 100): -187.700\n",
            "Episode 32200 Average Reward (last 100): -179.480\n",
            "Episode 32300 Average Reward (last 100): -191.910\n",
            "Episode 32400 Average Reward (last 100): -183.750\n",
            "Episode 32500 Average Reward (last 100): -179.640\n",
            "Episode 32600 Average Reward (last 100): -185.750\n",
            "Episode 32700 Average Reward (last 100): -189.880\n",
            "Episode 32800 Average Reward (last 100): -181.660\n",
            "Episode 32900 Average Reward (last 100): -181.680\n",
            "Episode 33000 Average Reward (last 100): -187.740\n",
            "Episode 33100 Average Reward (last 100): -183.600\n",
            "Episode 33200 Average Reward (last 100): -207.380\n",
            "Episode 33300 Average Reward (last 100): -197.530\n",
            "Episode 33400 Average Reward (last 100): -191.880\n",
            "Episode 33500 Average Reward (last 100): -225.180\n",
            "Episode 33600 Average Reward (last 100): -185.740\n",
            "Episode 33700 Average Reward (last 100): -209.670\n",
            "Episode 33800 Average Reward (last 100): -243.330\n",
            "Episode 33900 Average Reward (last 100): -179.700\n",
            "Episode 34000 Average Reward (last 100): -218.920\n",
            "Episode 34100 Average Reward (last 100): -215.790\n",
            "Episode 34200 Average Reward (last 100): -172.290\n",
            "Episode 34300 Average Reward (last 100): -167.150\n",
            "Episode 34400 Average Reward (last 100): -158.840\n",
            "Episode 34500 Average Reward (last 100): -177.170\n",
            "Episode 34600 Average Reward (last 100): -176.820\n",
            "Episode 34700 Average Reward (last 100): -179.560\n",
            "Episode 34800 Average Reward (last 100): -194.620\n",
            "Episode 34900 Average Reward (last 100): -211.040\n",
            "Episode 35000 Average Reward (last 100): -188.820\n",
            "Episode 35100 Average Reward (last 100): -164.890\n",
            "Episode 35200 Average Reward (last 100): -170.970\n",
            "Episode 35300 Average Reward (last 100): -163.000\n",
            "Episode 35400 Average Reward (last 100): -173.170\n",
            "Episode 35500 Average Reward (last 100): -179.050\n",
            "Episode 35600 Average Reward (last 100): -167.290\n",
            "Episode 35700 Average Reward (last 100): -160.810\n",
            "Episode 35800 Average Reward (last 100): -160.930\n",
            "Episode 35900 Average Reward (last 100): -173.100\n",
            "Episode 36000 Average Reward (last 100): -185.140\n",
            "Episode 36100 Average Reward (last 100): -148.100\n",
            "Episode 36200 Average Reward (last 100): -158.710\n",
            "Episode 36300 Average Reward (last 100): -166.910\n",
            "Episode 36400 Average Reward (last 100): -171.250\n",
            "Episode 36500 Average Reward (last 100): -160.850\n",
            "Episode 36600 Average Reward (last 100): -173.300\n",
            "Episode 36700 Average Reward (last 100): -175.230\n",
            "Episode 36800 Average Reward (last 100): -165.090\n",
            "Episode 36900 Average Reward (last 100): -150.900\n",
            "Episode 37000 Average Reward (last 100): -160.880\n",
            "Episode 37100 Average Reward (last 100): -164.850\n",
            "Episode 37200 Average Reward (last 100): -162.930\n",
            "Episode 37300 Average Reward (last 100): -173.200\n",
            "Episode 37400 Average Reward (last 100): -171.120\n",
            "Episode 37500 Average Reward (last 100): -210.550\n",
            "Episode 37600 Average Reward (last 100): -193.180\n",
            "Episode 37700 Average Reward (last 100): -200.580\n",
            "Episode 37800 Average Reward (last 100): -226.430\n",
            "Episode 37900 Average Reward (last 100): -191.080\n",
            "Episode 38000 Average Reward (last 100): -179.380\n",
            "Episode 38100 Average Reward (last 100): -254.120\n",
            "Episode 38200 Average Reward (last 100): -177.030\n",
            "Episode 38300 Average Reward (last 100): -165.000\n",
            "Episode 38400 Average Reward (last 100): -191.120\n",
            "Episode 38500 Average Reward (last 100): -171.040\n",
            "Episode 38600 Average Reward (last 100): -195.140\n",
            "Episode 38700 Average Reward (last 100): -182.590\n",
            "Episode 38800 Average Reward (last 100): -189.240\n",
            "Episode 38900 Average Reward (last 100): -193.230\n",
            "Episode 39000 Average Reward (last 100): -167.100\n",
            "Episode 39100 Average Reward (last 100): -167.120\n",
            "Episode 39200 Average Reward (last 100): -156.650\n",
            "Episode 39300 Average Reward (last 100): -181.520\n",
            "Episode 39400 Average Reward (last 100): -169.240\n",
            "Episode 39500 Average Reward (last 100): -198.260\n",
            "Episode 39600 Average Reward (last 100): -177.210\n",
            "Episode 39700 Average Reward (last 100): -159.030\n",
            "Episode 39800 Average Reward (last 100): -162.850\n",
            "Episode 39900 Average Reward (last 100): -171.360\n",
            "Episode 40000 Average Reward (last 100): -165.150\n",
            "Episode 40100 Average Reward (last 100): -156.990\n",
            "Episode 40200 Average Reward (last 100): -162.760\n",
            "Episode 40300 Average Reward (last 100): -164.930\n",
            "Episode 40400 Average Reward (last 100): -164.940\n",
            "Episode 40500 Average Reward (last 100): -205.730\n",
            "Episode 40600 Average Reward (last 100): -188.910\n",
            "Episode 40700 Average Reward (last 100): -179.550\n",
            "Episode 40800 Average Reward (last 100): -171.250\n",
            "Episode 40900 Average Reward (last 100): -222.890\n",
            "Episode 41000 Average Reward (last 100): -173.200\n",
            "Episode 41100 Average Reward (last 100): -162.860\n",
            "Episode 41200 Average Reward (last 100): -156.640\n",
            "Episode 41300 Average Reward (last 100): -158.610\n",
            "Episode 41400 Average Reward (last 100): -177.440\n",
            "Episode 41500 Average Reward (last 100): -171.190\n",
            "Episode 41600 Average Reward (last 100): -158.740\n",
            "Episode 41700 Average Reward (last 100): -168.960\n",
            "Episode 41800 Average Reward (last 100): -167.110\n",
            "Episode 41900 Average Reward (last 100): -158.860\n",
            "Episode 42000 Average Reward (last 100): -150.600\n",
            "Episode 42100 Average Reward (last 100): -202.610\n",
            "Episode 42200 Average Reward (last 100): -167.240\n",
            "Episode 42300 Average Reward (last 100): -160.820\n",
            "Episode 42400 Average Reward (last 100): -169.060\n",
            "Episode 42500 Average Reward (last 100): -158.720\n",
            "Episode 42600 Average Reward (last 100): -158.610\n",
            "Episode 42700 Average Reward (last 100): -183.420\n",
            "Episode 42800 Average Reward (last 100): -183.390\n",
            "Episode 42900 Average Reward (last 100): -167.090\n",
            "Episode 43000 Average Reward (last 100): -156.600\n",
            "Episode 43100 Average Reward (last 100): -160.900\n",
            "Episode 43200 Average Reward (last 100): -171.310\n",
            "Episode 43300 Average Reward (last 100): -171.330\n",
            "Episode 43400 Average Reward (last 100): -179.420\n",
            "Episode 43500 Average Reward (last 100): -162.990\n",
            "Episode 43600 Average Reward (last 100): -160.940\n",
            "Episode 43700 Average Reward (last 100): -175.210\n",
            "Episode 43800 Average Reward (last 100): -173.410\n",
            "Episode 43900 Average Reward (last 100): -156.650\n",
            "Episode 44000 Average Reward (last 100): -181.370\n",
            "Episode 44100 Average Reward (last 100): -169.070\n",
            "Episode 44200 Average Reward (last 100): -167.070\n",
            "Episode 44300 Average Reward (last 100): -154.560\n",
            "Episode 44400 Average Reward (last 100): -179.210\n",
            "Episode 44500 Average Reward (last 100): -171.170\n",
            "Episode 44600 Average Reward (last 100): -150.180\n",
            "Episode 44700 Average Reward (last 100): -165.130\n",
            "Episode 44800 Average Reward (last 100): -163.020\n",
            "Episode 44900 Average Reward (last 100): -202.790\n",
            "Episode 45000 Average Reward (last 100): -181.320\n",
            "Episode 45100 Average Reward (last 100): -200.360\n",
            "Episode 45200 Average Reward (last 100): -165.230\n",
            "Episode 45300 Average Reward (last 100): -158.720\n",
            "Episode 45400 Average Reward (last 100): -171.180\n",
            "Episode 45500 Average Reward (last 100): -171.250\n",
            "Episode 45600 Average Reward (last 100): -165.220\n",
            "Episode 45700 Average Reward (last 100): -167.200\n",
            "Episode 45800 Average Reward (last 100): -204.920\n",
            "Episode 45900 Average Reward (last 100): -158.650\n",
            "Episode 46000 Average Reward (last 100): -192.110\n",
            "Episode 46100 Average Reward (last 100): -175.310\n",
            "Episode 46200 Average Reward (last 100): -173.300\n",
            "Episode 46300 Average Reward (last 100): -206.680\n",
            "Episode 46400 Average Reward (last 100): -160.980\n",
            "Episode 46500 Average Reward (last 100): -162.840\n",
            "Episode 46600 Average Reward (last 100): -171.240\n",
            "Episode 46700 Average Reward (last 100): -167.220\n",
            "Episode 46800 Average Reward (last 100): -171.240\n",
            "Episode 46900 Average Reward (last 100): -164.920\n",
            "Episode 47000 Average Reward (last 100): -175.420\n",
            "Episode 47100 Average Reward (last 100): -175.280\n",
            "Episode 47200 Average Reward (last 100): -148.520\n",
            "Episode 47300 Average Reward (last 100): -162.860\n",
            "Episode 47400 Average Reward (last 100): -163.040\n",
            "Episode 47500 Average Reward (last 100): -171.210\n",
            "Episode 47600 Average Reward (last 100): -162.850\n",
            "Episode 47700 Average Reward (last 100): -167.060\n",
            "Episode 47800 Average Reward (last 100): -150.900\n",
            "Episode 47900 Average Reward (last 100): -177.300\n",
            "Episode 48000 Average Reward (last 100): -164.940\n",
            "Episode 48100 Average Reward (last 100): -183.590\n",
            "Episode 48200 Average Reward (last 100): -168.960\n",
            "Episode 48300 Average Reward (last 100): -189.180\n",
            "Episode 48400 Average Reward (last 100): -189.200\n",
            "Episode 48500 Average Reward (last 100): -173.310\n",
            "Episode 48600 Average Reward (last 100): -181.370\n",
            "Episode 48700 Average Reward (last 100): -179.340\n",
            "Episode 48800 Average Reward (last 100): -169.040\n",
            "Episode 48900 Average Reward (last 100): -156.690\n",
            "Episode 49000 Average Reward (last 100): -169.150\n",
            "Episode 49100 Average Reward (last 100): -156.700\n",
            "Episode 49200 Average Reward (last 100): -156.810\n",
            "Episode 49300 Average Reward (last 100): -160.870\n",
            "Episode 49400 Average Reward (last 100): -150.490\n",
            "Episode 49500 Average Reward (last 100): -154.680\n",
            "Episode 49600 Average Reward (last 100): -173.220\n",
            "Episode 49700 Average Reward (last 100): -201.970\n",
            "Episode 49800 Average Reward (last 100): -158.880\n",
            "Episode 49900 Average Reward (last 100): -152.700\n",
            "Episode 50000 Average Reward (last 100): -154.540\n",
            "Episode 50100 Average Reward (last 100): -158.780\n",
            "Episode 50200 Average Reward (last 100): -163.100\n",
            "Episode 50300 Average Reward (last 100): -202.320\n",
            "Episode 50400 Average Reward (last 100): -150.540\n",
            "Episode 50500 Average Reward (last 100): -158.760\n",
            "Episode 50600 Average Reward (last 100): -167.160\n",
            "Episode 50700 Average Reward (last 100): -160.860\n",
            "Episode 50800 Average Reward (last 100): -156.820\n",
            "Episode 50900 Average Reward (last 100): -140.220\n",
            "Episode 51000 Average Reward (last 100): -152.610\n",
            "Episode 51100 Average Reward (last 100): -173.310\n",
            "Episode 51200 Average Reward (last 100): -160.810\n",
            "Episode 51300 Average Reward (last 100): -165.020\n",
            "Episode 51400 Average Reward (last 100): -144.360\n",
            "Episode 51500 Average Reward (last 100): -156.840\n",
            "Episode 51600 Average Reward (last 100): -177.010\n",
            "Episode 51700 Average Reward (last 100): -164.960\n",
            "Episode 51800 Average Reward (last 100): -156.620\n",
            "Episode 51900 Average Reward (last 100): -156.810\n",
            "Episode 52000 Average Reward (last 100): -154.660\n",
            "Episode 52100 Average Reward (last 100): -140.290\n",
            "Episode 52200 Average Reward (last 100): -158.850\n",
            "Episode 52300 Average Reward (last 100): -148.480\n",
            "Episode 52400 Average Reward (last 100): -167.160\n",
            "Episode 52500 Average Reward (last 100): -181.280\n",
            "Episode 52600 Average Reward (last 100): -158.600\n",
            "Episode 52700 Average Reward (last 100): -148.460\n",
            "Episode 52800 Average Reward (last 100): -156.540\n",
            "Episode 52900 Average Reward (last 100): -154.640\n",
            "Episode 53000 Average Reward (last 100): -165.030\n",
            "Episode 53100 Average Reward (last 100): -152.500\n",
            "Episode 53200 Average Reward (last 100): -163.020\n",
            "Episode 53300 Average Reward (last 100): -163.000\n",
            "Episode 53400 Average Reward (last 100): -173.240\n",
            "Episode 53500 Average Reward (last 100): -152.830\n",
            "Episode 53600 Average Reward (last 100): -162.840\n",
            "Episode 53700 Average Reward (last 100): -167.080\n",
            "Episode 53800 Average Reward (last 100): -171.260\n",
            "Episode 53900 Average Reward (last 100): -160.850\n",
            "Episode 54000 Average Reward (last 100): -166.840\n",
            "Episode 54100 Average Reward (last 100): -162.940\n",
            "Episode 54200 Average Reward (last 100): -154.630\n",
            "Episode 54300 Average Reward (last 100): -154.880\n",
            "Episode 54400 Average Reward (last 100): -148.530\n",
            "Episode 54500 Average Reward (last 100): -152.600\n",
            "Episode 54600 Average Reward (last 100): -169.330\n",
            "Episode 54700 Average Reward (last 100): -162.720\n",
            "Episode 54800 Average Reward (last 100): -162.810\n",
            "Episode 54900 Average Reward (last 100): -158.750\n",
            "Episode 55000 Average Reward (last 100): -163.010\n",
            "Episode 55100 Average Reward (last 100): -167.000\n",
            "Episode 55200 Average Reward (last 100): -162.870\n",
            "Episode 55300 Average Reward (last 100): -157.090\n",
            "Episode 55400 Average Reward (last 100): -152.660\n",
            "Episode 55500 Average Reward (last 100): -166.850\n",
            "Episode 55600 Average Reward (last 100): -158.650\n",
            "Episode 55700 Average Reward (last 100): -154.630\n",
            "Episode 55800 Average Reward (last 100): -150.710\n",
            "Episode 55900 Average Reward (last 100): -160.680\n",
            "Episode 56000 Average Reward (last 100): -152.320\n",
            "Episode 56100 Average Reward (last 100): -169.180\n",
            "Episode 56200 Average Reward (last 100): -183.560\n",
            "Episode 56300 Average Reward (last 100): -144.200\n",
            "Episode 56400 Average Reward (last 100): -148.430\n",
            "Episode 56500 Average Reward (last 100): -146.550\n",
            "Episode 56600 Average Reward (last 100): -168.900\n",
            "Episode 56700 Average Reward (last 100): -152.780\n",
            "Episode 56800 Average Reward (last 100): -156.710\n",
            "Episode 56900 Average Reward (last 100): -162.930\n",
            "Episode 57000 Average Reward (last 100): -154.550\n",
            "Episode 57100 Average Reward (last 100): -152.590\n",
            "Episode 57200 Average Reward (last 100): -156.560\n",
            "Episode 57300 Average Reward (last 100): -142.120\n",
            "Episode 57400 Average Reward (last 100): -166.960\n",
            "Episode 57500 Average Reward (last 100): -140.120\n",
            "Episode 57600 Average Reward (last 100): -164.940\n",
            "Episode 57700 Average Reward (last 100): -160.970\n",
            "Episode 57800 Average Reward (last 100): -165.030\n",
            "Episode 57900 Average Reward (last 100): -166.990\n",
            "Episode 58000 Average Reward (last 100): -164.920\n",
            "Episode 58100 Average Reward (last 100): -162.860\n",
            "Episode 58200 Average Reward (last 100): -156.620\n",
            "Episode 58300 Average Reward (last 100): -171.060\n",
            "Episode 58400 Average Reward (last 100): -169.140\n",
            "Episode 58500 Average Reward (last 100): -163.020\n",
            "Episode 58600 Average Reward (last 100): -156.630\n",
            "Episode 58700 Average Reward (last 100): -158.660\n",
            "Episode 58800 Average Reward (last 100): -150.500\n",
            "Episode 58900 Average Reward (last 100): -160.760\n",
            "Episode 59000 Average Reward (last 100): -169.060\n",
            "Episode 59100 Average Reward (last 100): -156.660\n",
            "Episode 59200 Average Reward (last 100): -162.940\n",
            "Episode 59300 Average Reward (last 100): -156.680\n",
            "Episode 59400 Average Reward (last 100): -148.540\n",
            "Episode 59500 Average Reward (last 100): -156.810\n",
            "Episode 59600 Average Reward (last 100): -160.550\n",
            "Episode 59700 Average Reward (last 100): -158.820\n",
            "Episode 59800 Average Reward (last 100): -162.840\n",
            "Episode 59900 Average Reward (last 100): -166.810\n",
            "Episode 60000 Average Reward (last 100): -169.320\n",
            "Episode 60100 Average Reward (last 100): -173.310\n",
            "Episode 60200 Average Reward (last 100): -165.140\n",
            "Episode 60300 Average Reward (last 100): -173.090\n",
            "Episode 60400 Average Reward (last 100): -165.060\n",
            "Episode 60500 Average Reward (last 100): -173.200\n",
            "Episode 60600 Average Reward (last 100): -162.910\n",
            "Episode 60700 Average Reward (last 100): -158.700\n",
            "Episode 60800 Average Reward (last 100): -169.080\n",
            "Episode 60900 Average Reward (last 100): -164.790\n",
            "Episode 61000 Average Reward (last 100): -146.380\n",
            "Episode 61100 Average Reward (last 100): -175.170\n",
            "Episode 61200 Average Reward (last 100): -163.060\n",
            "Episode 61300 Average Reward (last 100): -152.570\n",
            "Episode 61400 Average Reward (last 100): -156.890\n",
            "Episode 61500 Average Reward (last 100): -158.840\n",
            "Episode 61600 Average Reward (last 100): -162.870\n",
            "Episode 61700 Average Reward (last 100): -168.930\n",
            "Episode 61800 Average Reward (last 100): -144.350\n",
            "Episode 61900 Average Reward (last 100): -169.040\n",
            "Episode 62000 Average Reward (last 100): -156.590\n",
            "Episode 62100 Average Reward (last 100): -152.620\n",
            "Episode 62200 Average Reward (last 100): -156.800\n",
            "Episode 62300 Average Reward (last 100): -162.890\n",
            "Episode 62400 Average Reward (last 100): -160.810\n",
            "Episode 62500 Average Reward (last 100): -150.500\n",
            "Episode 62600 Average Reward (last 100): -156.440\n",
            "Episode 62700 Average Reward (last 100): -156.850\n",
            "Episode 62800 Average Reward (last 100): -162.940\n",
            "Episode 62900 Average Reward (last 100): -152.700\n",
            "Episode 63000 Average Reward (last 100): -164.690\n",
            "Episode 63100 Average Reward (last 100): -164.950\n",
            "Episode 63200 Average Reward (last 100): -165.100\n",
            "Episode 63300 Average Reward (last 100): -162.880\n",
            "Episode 63400 Average Reward (last 100): -173.170\n",
            "Episode 63500 Average Reward (last 100): -156.740\n",
            "Episode 63600 Average Reward (last 100): -150.320\n",
            "Episode 63700 Average Reward (last 100): -175.240\n",
            "Episode 63800 Average Reward (last 100): -150.580\n",
            "Episode 63900 Average Reward (last 100): -156.720\n",
            "Episode 64000 Average Reward (last 100): -171.120\n",
            "Episode 64100 Average Reward (last 100): -154.530\n",
            "Episode 64200 Average Reward (last 100): -160.800\n",
            "Episode 64300 Average Reward (last 100): -146.230\n",
            "Episode 64400 Average Reward (last 100): -154.620\n",
            "Episode 64500 Average Reward (last 100): -150.770\n",
            "Episode 64600 Average Reward (last 100): -142.250\n",
            "Episode 64700 Average Reward (last 100): -160.910\n",
            "Episode 64800 Average Reward (last 100): -158.780\n",
            "Episode 64900 Average Reward (last 100): -165.020\n",
            "Episode 65000 Average Reward (last 100): -146.390\n",
            "Episode 65100 Average Reward (last 100): -146.140\n",
            "Episode 65200 Average Reward (last 100): -158.710\n",
            "Episode 65300 Average Reward (last 100): -171.110\n",
            "Episode 65400 Average Reward (last 100): -160.780\n",
            "Episode 65500 Average Reward (last 100): -148.480\n",
            "Episode 65600 Average Reward (last 100): -163.020\n",
            "Episode 65700 Average Reward (last 100): -148.490\n",
            "Episode 65800 Average Reward (last 100): -162.880\n",
            "Episode 65900 Average Reward (last 100): -164.790\n",
            "Episode 66000 Average Reward (last 100): -156.530\n",
            "Episode 66100 Average Reward (last 100): -167.010\n",
            "Episode 66200 Average Reward (last 100): -146.680\n",
            "Episode 66300 Average Reward (last 100): -158.630\n",
            "Episode 66400 Average Reward (last 100): -158.890\n",
            "Episode 66500 Average Reward (last 100): -159.000\n",
            "Episode 66600 Average Reward (last 100): -162.680\n",
            "Episode 66700 Average Reward (last 100): -154.590\n",
            "Episode 66800 Average Reward (last 100): -160.810\n",
            "Episode 66900 Average Reward (last 100): -160.990\n",
            "Episode 67000 Average Reward (last 100): -152.570\n",
            "Episode 67100 Average Reward (last 100): -160.590\n",
            "Episode 67200 Average Reward (last 100): -158.650\n",
            "Episode 67300 Average Reward (last 100): -169.050\n",
            "Episode 67400 Average Reward (last 100): -160.800\n",
            "Episode 67500 Average Reward (last 100): -173.130\n",
            "Episode 67600 Average Reward (last 100): -152.680\n",
            "Episode 67700 Average Reward (last 100): -146.580\n",
            "Episode 67800 Average Reward (last 100): -152.730\n",
            "Episode 67900 Average Reward (last 100): -154.870\n",
            "Episode 68000 Average Reward (last 100): -162.890\n",
            "Episode 68100 Average Reward (last 100): -150.450\n",
            "Episode 68200 Average Reward (last 100): -156.890\n",
            "Episode 68300 Average Reward (last 100): -166.920\n",
            "Episode 68400 Average Reward (last 100): -166.870\n",
            "Episode 68500 Average Reward (last 100): -156.800\n",
            "Episode 68600 Average Reward (last 100): -160.940\n",
            "Episode 68700 Average Reward (last 100): -173.360\n",
            "Episode 68800 Average Reward (last 100): -173.270\n",
            "Episode 68900 Average Reward (last 100): -154.510\n",
            "Episode 69000 Average Reward (last 100): -154.800\n",
            "Episode 69100 Average Reward (last 100): -166.840\n",
            "Episode 69200 Average Reward (last 100): -156.740\n",
            "Episode 69300 Average Reward (last 100): -154.730\n",
            "Episode 69400 Average Reward (last 100): -148.340\n",
            "Episode 69500 Average Reward (last 100): -160.990\n",
            "Episode 69600 Average Reward (last 100): -156.720\n",
            "Episode 69700 Average Reward (last 100): -160.700\n",
            "Episode 69800 Average Reward (last 100): -152.410\n",
            "Episode 69900 Average Reward (last 100): -162.900\n",
            "Episode 70000 Average Reward (last 100): -170.990\n",
            "Episode 70100 Average Reward (last 100): -150.390\n",
            "Episode 70200 Average Reward (last 100): -152.750\n",
            "Episode 70300 Average Reward (last 100): -156.660\n",
            "Episode 70400 Average Reward (last 100): -154.800\n",
            "Episode 70500 Average Reward (last 100): -171.140\n",
            "Episode 70600 Average Reward (last 100): -158.850\n",
            "Episode 70700 Average Reward (last 100): -154.490\n",
            "Episode 70800 Average Reward (last 100): -162.970\n",
            "Episode 70900 Average Reward (last 100): -150.590\n",
            "Episode 71000 Average Reward (last 100): -160.830\n",
            "Episode 71100 Average Reward (last 100): -162.790\n",
            "Episode 71200 Average Reward (last 100): -156.840\n",
            "Episode 71300 Average Reward (last 100): -171.280\n",
            "Episode 71400 Average Reward (last 100): -167.050\n",
            "Episode 71500 Average Reward (last 100): -177.310\n",
            "Episode 71600 Average Reward (last 100): -150.630\n",
            "Episode 71700 Average Reward (last 100): -154.420\n",
            "Episode 71800 Average Reward (last 100): -154.720\n",
            "Episode 71900 Average Reward (last 100): -163.110\n",
            "Episode 72000 Average Reward (last 100): -165.030\n",
            "Episode 72100 Average Reward (last 100): -154.450\n",
            "Episode 72200 Average Reward (last 100): -164.910\n",
            "Episode 72300 Average Reward (last 100): -152.730\n",
            "Episode 72400 Average Reward (last 100): -164.890\n",
            "Episode 72500 Average Reward (last 100): -162.990\n",
            "Episode 72600 Average Reward (last 100): -164.980\n",
            "Episode 72700 Average Reward (last 100): -156.680\n",
            "Episode 72800 Average Reward (last 100): -177.180\n",
            "Episode 72900 Average Reward (last 100): -162.920\n",
            "Episode 73000 Average Reward (last 100): -158.810\n",
            "Episode 73100 Average Reward (last 100): -165.120\n",
            "Episode 73200 Average Reward (last 100): -162.910\n",
            "Episode 73300 Average Reward (last 100): -156.850\n",
            "Episode 73400 Average Reward (last 100): -160.690\n",
            "Episode 73500 Average Reward (last 100): -164.930\n",
            "Episode 73600 Average Reward (last 100): -158.660\n",
            "Episode 73700 Average Reward (last 100): -169.110\n",
            "Episode 73800 Average Reward (last 100): -164.890\n",
            "Episode 73900 Average Reward (last 100): -158.540\n",
            "Episode 74000 Average Reward (last 100): -160.970\n",
            "Episode 74100 Average Reward (last 100): -161.040\n",
            "Episode 74200 Average Reward (last 100): -150.610\n",
            "Episode 74300 Average Reward (last 100): -164.800\n",
            "Episode 74400 Average Reward (last 100): -168.990\n",
            "Episode 74500 Average Reward (last 100): -154.940\n",
            "Episode 74600 Average Reward (last 100): -154.870\n",
            "Episode 74700 Average Reward (last 100): -150.430\n",
            "Episode 74800 Average Reward (last 100): -154.720\n",
            "Episode 74900 Average Reward (last 100): -152.320\n",
            "Episode 75000 Average Reward (last 100): -150.650\n",
            "Episode 75100 Average Reward (last 100): -154.670\n",
            "Episode 75200 Average Reward (last 100): -167.120\n",
            "Episode 75300 Average Reward (last 100): -148.260\n",
            "Episode 75400 Average Reward (last 100): -173.280\n",
            "Episode 75500 Average Reward (last 100): -161.010\n",
            "Episode 75600 Average Reward (last 100): -152.450\n",
            "Episode 75700 Average Reward (last 100): -142.330\n",
            "Episode 75800 Average Reward (last 100): -158.790\n",
            "Episode 75900 Average Reward (last 100): -154.630\n",
            "Episode 76000 Average Reward (last 100): -156.890\n",
            "Episode 76100 Average Reward (last 100): -181.530\n",
            "Episode 76200 Average Reward (last 100): -162.850\n",
            "Episode 76300 Average Reward (last 100): -146.420\n",
            "Episode 76400 Average Reward (last 100): -156.700\n",
            "Episode 76500 Average Reward (last 100): -165.110\n",
            "Episode 76600 Average Reward (last 100): -156.450\n",
            "Episode 76700 Average Reward (last 100): -152.780\n",
            "Episode 76800 Average Reward (last 100): -166.930\n",
            "Episode 76900 Average Reward (last 100): -163.010\n",
            "Episode 77000 Average Reward (last 100): -160.790\n",
            "Episode 77100 Average Reward (last 100): -156.570\n",
            "Episode 77200 Average Reward (last 100): -171.140\n",
            "Episode 77300 Average Reward (last 100): -160.670\n",
            "Episode 77400 Average Reward (last 100): -160.670\n",
            "Episode 77500 Average Reward (last 100): -163.170\n",
            "Episode 77600 Average Reward (last 100): -158.830\n",
            "Episode 77700 Average Reward (last 100): -160.920\n",
            "Episode 77800 Average Reward (last 100): -167.100\n",
            "Episode 77900 Average Reward (last 100): -144.310\n",
            "Episode 78000 Average Reward (last 100): -181.340\n",
            "Episode 78100 Average Reward (last 100): -158.720\n",
            "Episode 78200 Average Reward (last 100): -160.720\n",
            "Episode 78300 Average Reward (last 100): -156.700\n",
            "Episode 78400 Average Reward (last 100): -152.680\n",
            "Episode 78500 Average Reward (last 100): -168.940\n",
            "Episode 78600 Average Reward (last 100): -148.550\n",
            "Episode 78700 Average Reward (last 100): -160.830\n",
            "Episode 78800 Average Reward (last 100): -167.140\n",
            "Episode 78900 Average Reward (last 100): -142.200\n",
            "Episode 79000 Average Reward (last 100): -165.160\n",
            "Episode 79100 Average Reward (last 100): -154.630\n",
            "Episode 79200 Average Reward (last 100): -158.860\n",
            "Episode 79300 Average Reward (last 100): -154.610\n",
            "Episode 79400 Average Reward (last 100): -150.490\n",
            "Episode 79500 Average Reward (last 100): -150.850\n",
            "Episode 79600 Average Reward (last 100): -162.910\n",
            "Episode 79700 Average Reward (last 100): -171.270\n",
            "Episode 79800 Average Reward (last 100): -163.010\n",
            "Episode 79900 Average Reward (last 100): -169.380\n",
            "Episode 80000 Average Reward (last 100): -162.970\n",
            "Episode 80100 Average Reward (last 100): -148.400\n",
            "Episode 80200 Average Reward (last 100): -150.550\n",
            "Episode 80300 Average Reward (last 100): -165.060\n",
            "Episode 80400 Average Reward (last 100): -158.540\n",
            "Episode 80500 Average Reward (last 100): -167.070\n",
            "Episode 80600 Average Reward (last 100): -156.900\n",
            "Episode 80700 Average Reward (last 100): -148.590\n",
            "Episode 80800 Average Reward (last 100): -181.470\n",
            "Episode 80900 Average Reward (last 100): -160.880\n",
            "Episode 81000 Average Reward (last 100): -156.820\n",
            "Episode 81100 Average Reward (last 100): -162.930\n",
            "Episode 81200 Average Reward (last 100): -169.100\n",
            "Episode 81300 Average Reward (last 100): -150.460\n",
            "Episode 81400 Average Reward (last 100): -156.650\n",
            "Episode 81500 Average Reward (last 100): -169.010\n",
            "Episode 81600 Average Reward (last 100): -154.630\n",
            "Episode 81700 Average Reward (last 100): -129.700\n",
            "Episode 81800 Average Reward (last 100): -142.120\n",
            "Episode 81900 Average Reward (last 100): -183.570\n",
            "Episode 82000 Average Reward (last 100): -164.740\n",
            "Episode 82100 Average Reward (last 100): -175.220\n",
            "Episode 82200 Average Reward (last 100): -169.350\n",
            "Episode 82300 Average Reward (last 100): -167.060\n",
            "Episode 82400 Average Reward (last 100): -148.090\n",
            "Episode 82500 Average Reward (last 100): -164.910\n",
            "Episode 82600 Average Reward (last 100): -161.030\n",
            "Episode 82700 Average Reward (last 100): -148.240\n",
            "Episode 82800 Average Reward (last 100): -179.400\n",
            "Episode 82900 Average Reward (last 100): -146.520\n",
            "Episode 83000 Average Reward (last 100): -156.690\n",
            "Episode 83100 Average Reward (last 100): -157.040\n",
            "Episode 83200 Average Reward (last 100): -154.820\n",
            "Episode 83300 Average Reward (last 100): -152.680\n",
            "Episode 83400 Average Reward (last 100): -156.670\n",
            "Episode 83500 Average Reward (last 100): -154.520\n",
            "Episode 83600 Average Reward (last 100): -152.570\n",
            "Episode 83700 Average Reward (last 100): -154.500\n",
            "Episode 83800 Average Reward (last 100): -160.760\n",
            "Episode 83900 Average Reward (last 100): -160.690\n",
            "Episode 84000 Average Reward (last 100): -158.950\n",
            "Episode 84100 Average Reward (last 100): -161.120\n",
            "Episode 84200 Average Reward (last 100): -156.370\n",
            "Episode 84300 Average Reward (last 100): -166.860\n",
            "Episode 84400 Average Reward (last 100): -160.830\n",
            "Episode 84500 Average Reward (last 100): -146.590\n",
            "Episode 84600 Average Reward (last 100): -156.590\n",
            "Episode 84700 Average Reward (last 100): -150.560\n",
            "Episode 84800 Average Reward (last 100): -142.060\n",
            "Episode 84900 Average Reward (last 100): -150.590\n",
            "Episode 85000 Average Reward (last 100): -152.600\n",
            "Episode 85100 Average Reward (last 100): -160.970\n",
            "Episode 85200 Average Reward (last 100): -154.510\n",
            "Episode 85300 Average Reward (last 100): -158.650\n",
            "Episode 85400 Average Reward (last 100): -160.710\n",
            "Episode 85500 Average Reward (last 100): -164.810\n",
            "Episode 85600 Average Reward (last 100): -162.890\n",
            "Episode 85700 Average Reward (last 100): -160.990\n",
            "Episode 85800 Average Reward (last 100): -158.780\n",
            "Episode 85900 Average Reward (last 100): -156.690\n",
            "Episode 86000 Average Reward (last 100): -164.980\n",
            "Episode 86100 Average Reward (last 100): -160.860\n",
            "Episode 86200 Average Reward (last 100): -163.020\n",
            "Episode 86300 Average Reward (last 100): -158.800\n",
            "Episode 86400 Average Reward (last 100): -150.400\n",
            "Episode 86500 Average Reward (last 100): -144.290\n",
            "Episode 86600 Average Reward (last 100): -160.710\n",
            "Episode 86700 Average Reward (last 100): -167.050\n",
            "Episode 86800 Average Reward (last 100): -175.300\n",
            "Episode 86900 Average Reward (last 100): -166.770\n",
            "Episode 87000 Average Reward (last 100): -144.170\n",
            "Episode 87100 Average Reward (last 100): -164.850\n",
            "Episode 87200 Average Reward (last 100): -154.750\n",
            "Episode 87300 Average Reward (last 100): -146.550\n",
            "Episode 87400 Average Reward (last 100): -154.670\n",
            "Episode 87500 Average Reward (last 100): -167.350\n",
            "Episode 87600 Average Reward (last 100): -148.520\n",
            "Episode 87700 Average Reward (last 100): -162.760\n",
            "Episode 87800 Average Reward (last 100): -165.020\n",
            "Episode 87900 Average Reward (last 100): -152.630\n",
            "Episode 88000 Average Reward (last 100): -150.490\n",
            "Episode 88100 Average Reward (last 100): -160.940\n",
            "Episode 88200 Average Reward (last 100): -152.840\n",
            "Episode 88300 Average Reward (last 100): -152.750\n",
            "Episode 88400 Average Reward (last 100): -163.050\n",
            "Episode 88500 Average Reward (last 100): -154.620\n",
            "Episode 88600 Average Reward (last 100): -150.400\n",
            "Episode 88700 Average Reward (last 100): -167.060\n",
            "Episode 88800 Average Reward (last 100): -160.790\n",
            "Episode 88900 Average Reward (last 100): -164.860\n",
            "Episode 89000 Average Reward (last 100): -146.390\n",
            "Episode 89100 Average Reward (last 100): -154.740\n",
            "Episode 89200 Average Reward (last 100): -156.630\n",
            "Episode 89300 Average Reward (last 100): -156.690\n",
            "Episode 89400 Average Reward (last 100): -160.780\n",
            "Episode 89500 Average Reward (last 100): -179.350\n",
            "Episode 89600 Average Reward (last 100): -154.640\n",
            "Episode 89700 Average Reward (last 100): -156.510\n",
            "Episode 89800 Average Reward (last 100): -165.000\n",
            "Episode 89900 Average Reward (last 100): -160.890\n",
            "Episode 90000 Average Reward (last 100): -162.490\n",
            "Episode 90100 Average Reward (last 100): -164.790\n",
            "Episode 90200 Average Reward (last 100): -158.870\n",
            "Episode 90300 Average Reward (last 100): -162.860\n",
            "Episode 90400 Average Reward (last 100): -152.590\n",
            "Episode 90500 Average Reward (last 100): -164.850\n",
            "Episode 90600 Average Reward (last 100): -154.650\n",
            "Episode 90700 Average Reward (last 100): -161.010\n",
            "Episode 90800 Average Reward (last 100): -152.480\n",
            "Episode 90900 Average Reward (last 100): -159.010\n",
            "Episode 91000 Average Reward (last 100): -173.200\n",
            "Episode 91100 Average Reward (last 100): -165.040\n",
            "Episode 91200 Average Reward (last 100): -170.900\n",
            "Episode 91300 Average Reward (last 100): -150.420\n",
            "Episode 91400 Average Reward (last 100): -146.640\n",
            "Episode 91500 Average Reward (last 100): -150.270\n",
            "Episode 91600 Average Reward (last 100): -162.880\n",
            "Episode 91700 Average Reward (last 100): -164.950\n",
            "Episode 91800 Average Reward (last 100): -177.320\n",
            "Episode 91900 Average Reward (last 100): -154.540\n",
            "Episode 92000 Average Reward (last 100): -154.900\n",
            "Episode 92100 Average Reward (last 100): -167.050\n",
            "Episode 92200 Average Reward (last 100): -170.860\n",
            "Episode 92300 Average Reward (last 100): -161.100\n",
            "Episode 92400 Average Reward (last 100): -158.650\n",
            "Episode 92500 Average Reward (last 100): -154.630\n",
            "Episode 92600 Average Reward (last 100): -158.910\n",
            "Episode 92700 Average Reward (last 100): -164.840\n",
            "Episode 92800 Average Reward (last 100): -173.220\n",
            "Episode 92900 Average Reward (last 100): -144.050\n",
            "Episode 93000 Average Reward (last 100): -162.860\n",
            "Episode 93100 Average Reward (last 100): -167.190\n",
            "Episode 93200 Average Reward (last 100): -144.330\n",
            "Episode 93300 Average Reward (last 100): -169.360\n",
            "Episode 93400 Average Reward (last 100): -164.860\n",
            "Episode 93500 Average Reward (last 100): -154.510\n",
            "Episode 93600 Average Reward (last 100): -169.090\n",
            "Episode 93700 Average Reward (last 100): -156.750\n",
            "Episode 93800 Average Reward (last 100): -144.380\n",
            "Episode 93900 Average Reward (last 100): -166.790\n",
            "Episode 94000 Average Reward (last 100): -144.410\n",
            "Episode 94100 Average Reward (last 100): -166.890\n",
            "Episode 94200 Average Reward (last 100): -165.100\n",
            "Episode 94300 Average Reward (last 100): -169.210\n",
            "Episode 94400 Average Reward (last 100): -154.660\n",
            "Episode 94500 Average Reward (last 100): -173.400\n",
            "Episode 94600 Average Reward (last 100): -152.360\n",
            "Episode 94700 Average Reward (last 100): -163.120\n",
            "Episode 94800 Average Reward (last 100): -175.210\n",
            "Episode 94900 Average Reward (last 100): -144.060\n",
            "Episode 95000 Average Reward (last 100): -165.100\n",
            "Episode 95100 Average Reward (last 100): -152.290\n",
            "Episode 95200 Average Reward (last 100): -161.050\n",
            "Episode 95300 Average Reward (last 100): -160.810\n",
            "Episode 95400 Average Reward (last 100): -154.760\n",
            "Episode 95500 Average Reward (last 100): -148.400\n",
            "Episode 95600 Average Reward (last 100): -150.460\n",
            "Episode 95700 Average Reward (last 100): -158.840\n",
            "Episode 95800 Average Reward (last 100): -156.690\n",
            "Episode 95900 Average Reward (last 100): -150.660\n",
            "Episode 96000 Average Reward (last 100): -148.500\n",
            "Episode 96100 Average Reward (last 100): -158.790\n",
            "Episode 96200 Average Reward (last 100): -148.500\n",
            "Episode 96300 Average Reward (last 100): -156.850\n",
            "Episode 96400 Average Reward (last 100): -156.680\n",
            "Episode 96500 Average Reward (last 100): -154.630\n",
            "Episode 96600 Average Reward (last 100): -156.700\n",
            "Episode 96700 Average Reward (last 100): -162.680\n",
            "Episode 96800 Average Reward (last 100): -158.650\n",
            "Episode 96900 Average Reward (last 100): -171.150\n",
            "Episode 97000 Average Reward (last 100): -162.880\n",
            "Episode 97100 Average Reward (last 100): -158.480\n",
            "Episode 97200 Average Reward (last 100): -154.680\n",
            "Episode 97300 Average Reward (last 100): -165.110\n",
            "Episode 97400 Average Reward (last 100): -148.470\n",
            "Episode 97500 Average Reward (last 100): -160.750\n",
            "Episode 97600 Average Reward (last 100): -156.690\n",
            "Episode 97700 Average Reward (last 100): -158.770\n",
            "Episode 97800 Average Reward (last 100): -160.600\n",
            "Episode 97900 Average Reward (last 100): -177.460\n",
            "Episode 98000 Average Reward (last 100): -167.090\n",
            "Episode 98100 Average Reward (last 100): -164.850\n",
            "Episode 98200 Average Reward (last 100): -156.890\n",
            "Episode 98300 Average Reward (last 100): -160.970\n",
            "Episode 98400 Average Reward (last 100): -156.750\n",
            "Episode 98500 Average Reward (last 100): -161.030\n",
            "Episode 98600 Average Reward (last 100): -159.010\n",
            "Episode 98700 Average Reward (last 100): -158.850\n",
            "Episode 98800 Average Reward (last 100): -166.950\n",
            "Episode 98900 Average Reward (last 100): -158.900\n",
            "Episode 99000 Average Reward (last 100): -154.340\n",
            "Episode 99100 Average Reward (last 100): -156.590\n",
            "Episode 99200 Average Reward (last 100): -158.850\n",
            "Episode 99300 Average Reward (last 100): -154.950\n",
            "Episode 99400 Average Reward (last 100): -137.860\n",
            "Episode 99500 Average Reward (last 100): -162.770\n",
            "Episode 99600 Average Reward (last 100): -162.890\n",
            "Episode 99700 Average Reward (last 100): -144.360\n",
            "Episode 99800 Average Reward (last 100): -169.220\n",
            "Episode 99900 Average Reward (last 100): -177.410\n",
            "Episode 100000 Average Reward (last 100): -158.830\n",
            "Últimos resultados: media = -179.8 , desvio padrao = 60.60082507689148\n",
            "Arquivo salvo: offPolicyD\n"
          ]
        }
      ],
      "source": [
        "if __name__ == \"__main__\":\n",
        "    r_max_plot = 10\n",
        "\n",
        "    EPISODES = 100000\n",
        "    LR = 0.01\n",
        "    GAMMA = 0.830525147061507\n",
        "    EPSILON = 0.05919712699520377\n",
        "\n",
        "    \n",
        "    # Roda o algoritmo Monte-Carlo para o problema de controle (ou seja, para achar a política ótima)\n",
        "    rewards, Qtable = run_montecarloOffP(env, EPISODES, GAMMA, EPSILON, render=False)\n",
        "    print(\"Últimos resultados: media =\", np.mean(rewards[-20:]), \", desvio padrao =\", np.std(rewards[-20:]))\n",
        "\n",
        "    # Mostra um gráfico de episódios x retornos (não descontados)\n",
        "    # Se quiser salvar, passe o nome do arquivo no 3o parâmetro\n",
        "    filename = f\"results/montecarloOffP-{ENV_NAME.lower()[0:8]}-ep{EPISODES}.png\"\n",
        "    plot_result(rewards, r_max_plot,100, 'offPolicyD')\n",
        "\n",
        "    # test_greedy_Q_policy(env, Qtable, 10, True)\n",
        "    env.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Execução Off-Policy(Weighted samples)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Otimiza parâmetros"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from numpy.random.mtrand import gamma\n",
        "\n",
        "import optuna\n",
        "\n",
        "\n",
        "\n",
        "ENV = gym.make(\"Taxi-v3\")\n",
        "\n",
        "\n",
        "# Esta função faz um treinamento com o Expected-SARSA, usando parâmetros sugeridos pelo Optuna.\n",
        "# Retorna a média dos retornos dos últimos 100 episódios.\n",
        "def train_values(trial : optuna.Trial):\n",
        "    \n",
        "    # chama os métodos do \"trial\" (tentativa) para sugerir valores para os parâmetros\n",
        "    gamma = trial.suggest_uniform('gamma', 0.02, 1.0)\n",
        "    eps = trial.suggest_uniform('epsilon', 0.01, 0.2)\n",
        "    #bins1 = trial.suggest_int('bins1', 5, 100)\n",
        "    #bins2 = trial.suggest_int('bins2', 5, 100)\n",
        "    \n",
        "    print(f\"\\nTRIAL #{trial.number}: eps={eps}, gamma={gamma}\")\n",
        "\n",
        "    # roda o algoritmo e recebe os retornos não-descontados\n",
        "    #env_wrapper = DiscreteObservationWrapper(ENV, [bins1,bins2])\n",
        "    (returns, _) = run_montecarloOffP_weighted(ENV, 20000, gamma, eps, render=False)\n",
        "    return sum(returns[-100:])/100 "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "study = optuna.create_study(direction='maximize', \n",
        "                            storage='sqlite:///optuna_studies.db', \n",
        "                            study_name= 'new_MC_offpolice_weighted', \n",
        "                            load_if_exists=True)\n",
        "study.optimize(train_values, n_trials=20)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Execução"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "env = gym.make(\"Taxi-v3\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Episode 100 Average Reward (last 100): -200.000\n",
            "Episode 200 Average Reward (last 100): -306.200\n",
            "Episode 300 Average Reward (last 100): -484.400\n",
            "Episode 400 Average Reward (last 100): -608.780\n",
            "Episode 500 Average Reward (last 100): -694.820\n",
            "Episode 600 Average Reward (last 100): -502.130\n",
            "Episode 700 Average Reward (last 100): -661.790\n",
            "Episode 800 Average Reward (last 100): -431.660\n",
            "Episode 900 Average Reward (last 100): -413.570\n",
            "Episode 1000 Average Reward (last 100): -484.310\n",
            "Episode 1100 Average Reward (last 100): -270.290\n",
            "Episode 1200 Average Reward (last 100): -306.380\n",
            "Episode 1300 Average Reward (last 100): -342.020\n",
            "Episode 1400 Average Reward (last 100): -325.190\n",
            "Episode 1500 Average Reward (last 100): -413.570\n",
            "Episode 1600 Average Reward (last 100): -359.480\n",
            "Episode 1700 Average Reward (last 100): -322.760\n",
            "Episode 1800 Average Reward (last 100): -411.860\n",
            "Episode 1900 Average Reward (last 100): -355.790\n",
            "Episode 2000 Average Reward (last 100): -478.820\n",
            "Episode 2100 Average Reward (last 100): -268.220\n",
            "Episode 2200 Average Reward (last 100): -269.570\n",
            "Episode 2300 Average Reward (last 100): -287.570\n",
            "Episode 2400 Average Reward (last 100): -323.570\n",
            "Episode 2500 Average Reward (last 100): -217.910\n",
            "Episode 2600 Average Reward (last 100): -375.500\n",
            "Episode 2700 Average Reward (last 100): -358.400\n",
            "Episode 2800 Average Reward (last 100): -270.200\n",
            "Episode 2900 Average Reward (last 100): -240.410\n",
            "Episode 3000 Average Reward (last 100): -173.540\n",
            "Episode 3100 Average Reward (last 100): -220.560\n",
            "Episode 3200 Average Reward (last 100): -201.820\n",
            "Episode 3300 Average Reward (last 100): -225.480\n",
            "Episode 3400 Average Reward (last 100): -239.510\n",
            "Episode 3500 Average Reward (last 100): -187.840\n",
            "Episode 3600 Average Reward (last 100): -190.000\n",
            "Episode 3700 Average Reward (last 100): -187.830\n",
            "Episode 3800 Average Reward (last 100): -187.910\n",
            "Episode 3900 Average Reward (last 100): -197.880\n",
            "Episode 4000 Average Reward (last 100): -181.720\n",
            "Episode 4100 Average Reward (last 100): -187.490\n",
            "Episode 4200 Average Reward (last 100): -171.340\n",
            "Episode 4300 Average Reward (last 100): -195.430\n",
            "Episode 4400 Average Reward (last 100): -173.410\n",
            "Episode 4500 Average Reward (last 100): -177.750\n",
            "Episode 4600 Average Reward (last 100): -203.680\n",
            "Episode 4700 Average Reward (last 100): -167.550\n",
            "Episode 4800 Average Reward (last 100): -171.420\n",
            "Episode 4900 Average Reward (last 100): -267.440\n",
            "Episode 5000 Average Reward (last 100): -202.320\n",
            "Episode 5100 Average Reward (last 100): -207.490\n",
            "Episode 5200 Average Reward (last 100): -175.670\n",
            "Episode 5300 Average Reward (last 100): -179.610\n",
            "Episode 5400 Average Reward (last 100): -193.670\n",
            "Episode 5500 Average Reward (last 100): -189.110\n",
            "Episode 5600 Average Reward (last 100): -217.160\n",
            "Episode 5700 Average Reward (last 100): -196.150\n",
            "Episode 5800 Average Reward (last 100): -160.550\n",
            "Episode 5900 Average Reward (last 100): -163.230\n",
            "Episode 6000 Average Reward (last 100): -165.280\n",
            "Episode 6100 Average Reward (last 100): -173.350\n",
            "Episode 6200 Average Reward (last 100): -163.250\n",
            "Episode 6300 Average Reward (last 100): -187.020\n",
            "Episode 6400 Average Reward (last 100): -169.290\n",
            "Episode 6500 Average Reward (last 100): -161.260\n",
            "Episode 6600 Average Reward (last 100): -167.110\n",
            "Episode 6700 Average Reward (last 100): -182.810\n",
            "Episode 6800 Average Reward (last 100): -188.830\n",
            "Episode 6900 Average Reward (last 100): -167.280\n",
            "Episode 7000 Average Reward (last 100): -169.650\n",
            "Episode 7100 Average Reward (last 100): -173.630\n",
            "Episode 7200 Average Reward (last 100): -152.700\n",
            "Episode 7300 Average Reward (last 100): -157.950\n",
            "Episode 7400 Average Reward (last 100): -154.630\n",
            "Episode 7500 Average Reward (last 100): -152.860\n",
            "Episode 7600 Average Reward (last 100): -149.000\n",
            "Episode 7700 Average Reward (last 100): -154.790\n",
            "Episode 7800 Average Reward (last 100): -158.880\n",
            "Episode 7900 Average Reward (last 100): -164.890\n",
            "Episode 8000 Average Reward (last 100): -154.800\n",
            "Episode 8100 Average Reward (last 100): -154.840\n",
            "Episode 8200 Average Reward (last 100): -146.760\n",
            "Episode 8300 Average Reward (last 100): -142.400\n",
            "Episode 8400 Average Reward (last 100): -177.230\n",
            "Episode 8500 Average Reward (last 100): -203.360\n",
            "Episode 8600 Average Reward (last 100): -178.850\n",
            "Episode 8700 Average Reward (last 100): -194.730\n",
            "Episode 8800 Average Reward (last 100): -150.520\n",
            "Episode 8900 Average Reward (last 100): -231.470\n",
            "Episode 9000 Average Reward (last 100): -221.650\n",
            "Episode 9100 Average Reward (last 100): -150.090\n",
            "Episode 9200 Average Reward (last 100): -214.300\n",
            "Episode 9300 Average Reward (last 100): -148.570\n",
            "Episode 9400 Average Reward (last 100): -202.700\n",
            "Episode 9500 Average Reward (last 100): -158.770\n",
            "Episode 9600 Average Reward (last 100): -150.760\n",
            "Episode 9700 Average Reward (last 100): -154.680\n",
            "Episode 9800 Average Reward (last 100): -154.500\n",
            "Episode 9900 Average Reward (last 100): -157.330\n",
            "Episode 10000 Average Reward (last 100): -146.640\n",
            "Episode 10100 Average Reward (last 100): -144.470\n",
            "Episode 10200 Average Reward (last 100): -150.720\n",
            "Episode 10300 Average Reward (last 100): -163.090\n",
            "Episode 10400 Average Reward (last 100): -148.740\n",
            "Episode 10500 Average Reward (last 100): -146.600\n",
            "Episode 10600 Average Reward (last 100): -146.860\n",
            "Episode 10700 Average Reward (last 100): -152.470\n",
            "Episode 10800 Average Reward (last 100): -156.720\n",
            "Episode 10900 Average Reward (last 100): -154.680\n",
            "Episode 11000 Average Reward (last 100): -171.140\n",
            "Episode 11100 Average Reward (last 100): -151.020\n",
            "Episode 11200 Average Reward (last 100): -150.560\n",
            "Episode 11300 Average Reward (last 100): -138.180\n",
            "Episode 11400 Average Reward (last 100): -148.750\n",
            "Episode 11500 Average Reward (last 100): -213.610\n",
            "Episode 11600 Average Reward (last 100): -225.480\n",
            "Episode 11700 Average Reward (last 100): -156.880\n",
            "Episode 11800 Average Reward (last 100): -167.410\n",
            "Episode 11900 Average Reward (last 100): -144.560\n",
            "Episode 12000 Average Reward (last 100): -190.300\n",
            "Episode 12100 Average Reward (last 100): -152.550\n",
            "Episode 12200 Average Reward (last 100): -160.920\n",
            "Episode 12300 Average Reward (last 100): -148.600\n",
            "Episode 12400 Average Reward (last 100): -156.780\n",
            "Episode 12500 Average Reward (last 100): -150.760\n",
            "Episode 12600 Average Reward (last 100): -136.720\n",
            "Episode 12700 Average Reward (last 100): -144.830\n",
            "Episode 12800 Average Reward (last 100): -144.670\n",
            "Episode 12900 Average Reward (last 100): -138.350\n",
            "Episode 13000 Average Reward (last 100): -146.530\n",
            "Episode 13100 Average Reward (last 100): -166.980\n",
            "Episode 13200 Average Reward (last 100): -136.400\n",
            "Episode 13300 Average Reward (last 100): -150.990\n",
            "Episode 13400 Average Reward (last 100): -154.760\n",
            "Episode 13500 Average Reward (last 100): -140.670\n",
            "Episode 13600 Average Reward (last 100): -145.280\n",
            "Episode 13700 Average Reward (last 100): -142.130\n",
            "Episode 13800 Average Reward (last 100): -154.610\n",
            "Episode 13900 Average Reward (last 100): -146.560\n",
            "Episode 14000 Average Reward (last 100): -150.340\n",
            "Episode 14100 Average Reward (last 100): -163.130\n",
            "Episode 14200 Average Reward (last 100): -146.140\n",
            "Episode 14300 Average Reward (last 100): -168.560\n",
            "Episode 14400 Average Reward (last 100): -142.910\n",
            "Episode 14500 Average Reward (last 100): -142.340\n",
            "Episode 14600 Average Reward (last 100): -148.540\n",
            "Episode 14700 Average Reward (last 100): -152.570\n",
            "Episode 14800 Average Reward (last 100): -148.780\n",
            "Episode 14900 Average Reward (last 100): -152.970\n",
            "Episode 15000 Average Reward (last 100): -142.340\n",
            "Episode 15100 Average Reward (last 100): -138.250\n",
            "Episode 15200 Average Reward (last 100): -131.930\n",
            "Episode 15300 Average Reward (last 100): -142.200\n",
            "Episode 15400 Average Reward (last 100): -136.070\n",
            "Episode 15500 Average Reward (last 100): -144.300\n",
            "Episode 15600 Average Reward (last 100): -130.240\n",
            "Episode 15700 Average Reward (last 100): -152.370\n",
            "Episode 15800 Average Reward (last 100): -146.290\n",
            "Episode 15900 Average Reward (last 100): -154.730\n",
            "Episode 16000 Average Reward (last 100): -133.780\n",
            "Episode 16100 Average Reward (last 100): -163.050\n",
            "Episode 16200 Average Reward (last 100): -132.130\n",
            "Episode 16300 Average Reward (last 100): -138.340\n",
            "Episode 16400 Average Reward (last 100): -146.050\n",
            "Episode 16500 Average Reward (last 100): -146.900\n",
            "Episode 16600 Average Reward (last 100): -150.650\n",
            "Episode 16700 Average Reward (last 100): -129.680\n",
            "Episode 16800 Average Reward (last 100): -157.180\n",
            "Episode 16900 Average Reward (last 100): -136.030\n",
            "Episode 17000 Average Reward (last 100): -138.490\n",
            "Episode 17100 Average Reward (last 100): -167.260\n",
            "Episode 17200 Average Reward (last 100): -158.200\n",
            "Episode 17300 Average Reward (last 100): -153.930\n",
            "Episode 17400 Average Reward (last 100): -160.780\n",
            "Episode 17500 Average Reward (last 100): -154.690\n",
            "Episode 17600 Average Reward (last 100): -148.550\n",
            "Episode 17700 Average Reward (last 100): -148.670\n",
            "Episode 17800 Average Reward (last 100): -175.550\n",
            "Episode 17900 Average Reward (last 100): -168.480\n",
            "Episode 18000 Average Reward (last 100): -144.810\n",
            "Episode 18100 Average Reward (last 100): -138.310\n",
            "Episode 18200 Average Reward (last 100): -160.860\n",
            "Episode 18300 Average Reward (last 100): -144.190\n",
            "Episode 18400 Average Reward (last 100): -150.260\n",
            "Episode 18500 Average Reward (last 100): -158.800\n",
            "Episode 18600 Average Reward (last 100): -150.440\n",
            "Episode 18700 Average Reward (last 100): -142.580\n",
            "Episode 18800 Average Reward (last 100): -138.260\n",
            "Episode 18900 Average Reward (last 100): -148.960\n",
            "Episode 19000 Average Reward (last 100): -142.240\n",
            "Episode 19100 Average Reward (last 100): -154.620\n",
            "Episode 19200 Average Reward (last 100): -138.730\n",
            "Episode 19300 Average Reward (last 100): -154.970\n",
            "Episode 19400 Average Reward (last 100): -148.700\n",
            "Episode 19500 Average Reward (last 100): -142.830\n",
            "Episode 19600 Average Reward (last 100): -155.020\n",
            "Episode 19700 Average Reward (last 100): -153.090\n",
            "Episode 19800 Average Reward (last 100): -133.790\n",
            "Episode 19900 Average Reward (last 100): -144.790\n",
            "Episode 20000 Average Reward (last 100): -161.470\n",
            "Episode 20100 Average Reward (last 100): -188.520\n",
            "Episode 20200 Average Reward (last 100): -179.900\n",
            "Episode 20300 Average Reward (last 100): -126.130\n",
            "Episode 20400 Average Reward (last 100): -136.290\n",
            "Episode 20500 Average Reward (last 100): -142.340\n",
            "Episode 20600 Average Reward (last 100): -144.600\n",
            "Episode 20700 Average Reward (last 100): -132.400\n",
            "Episode 20800 Average Reward (last 100): -135.910\n",
            "Episode 20900 Average Reward (last 100): -168.340\n",
            "Episode 21000 Average Reward (last 100): -130.400\n",
            "Episode 21100 Average Reward (last 100): -152.920\n",
            "Episode 21200 Average Reward (last 100): -140.420\n",
            "Episode 21300 Average Reward (last 100): -130.450\n",
            "Episode 21400 Average Reward (last 100): -144.220\n",
            "Episode 21500 Average Reward (last 100): -140.380\n",
            "Episode 21600 Average Reward (last 100): -127.860\n",
            "Episode 21700 Average Reward (last 100): -134.270\n",
            "Episode 21800 Average Reward (last 100): -132.090\n",
            "Episode 21900 Average Reward (last 100): -134.510\n",
            "Episode 22000 Average Reward (last 100): -146.550\n",
            "Episode 22100 Average Reward (last 100): -142.320\n",
            "Episode 22200 Average Reward (last 100): -144.240\n",
            "Episode 22300 Average Reward (last 100): -132.120\n",
            "Episode 22400 Average Reward (last 100): -136.140\n",
            "Episode 22500 Average Reward (last 100): -142.330\n",
            "Episode 22600 Average Reward (last 100): -129.990\n",
            "Episode 22700 Average Reward (last 100): -148.410\n",
            "Episode 22800 Average Reward (last 100): -126.190\n",
            "Episode 22900 Average Reward (last 100): -127.890\n",
            "Episode 23000 Average Reward (last 100): -132.200\n",
            "Episode 23100 Average Reward (last 100): -131.840\n",
            "Episode 23200 Average Reward (last 100): -130.210\n",
            "Episode 23300 Average Reward (last 100): -138.520\n",
            "Episode 23400 Average Reward (last 100): -142.780\n",
            "Episode 23500 Average Reward (last 100): -134.510\n",
            "Episode 23600 Average Reward (last 100): -134.550\n",
            "Episode 23700 Average Reward (last 100): -130.060\n",
            "Episode 23800 Average Reward (last 100): -128.030\n",
            "Episode 23900 Average Reward (last 100): -140.800\n",
            "Episode 24000 Average Reward (last 100): -132.340\n",
            "Episode 24100 Average Reward (last 100): -138.370\n",
            "Episode 24200 Average Reward (last 100): -121.910\n",
            "Episode 24300 Average Reward (last 100): -122.260\n",
            "Episode 24400 Average Reward (last 100): -125.970\n",
            "Episode 24500 Average Reward (last 100): -136.100\n",
            "Episode 24600 Average Reward (last 100): -150.340\n",
            "Episode 24700 Average Reward (last 100): -138.350\n",
            "Episode 24800 Average Reward (last 100): -140.170\n",
            "Episode 24900 Average Reward (last 100): -111.440\n",
            "Episode 25000 Average Reward (last 100): -156.950\n",
            "Episode 25100 Average Reward (last 100): -134.100\n",
            "Episode 25200 Average Reward (last 100): -150.910\n",
            "Episode 25300 Average Reward (last 100): -150.660\n",
            "Episode 25400 Average Reward (last 100): -117.700\n",
            "Episode 25500 Average Reward (last 100): -140.350\n",
            "Episode 25600 Average Reward (last 100): -156.960\n",
            "Episode 25700 Average Reward (last 100): -128.280\n",
            "Episode 25800 Average Reward (last 100): -132.210\n",
            "Episode 25900 Average Reward (last 100): -109.470\n",
            "Episode 26000 Average Reward (last 100): -107.670\n",
            "Episode 26100 Average Reward (last 100): -118.210\n",
            "Episode 26200 Average Reward (last 100): -115.490\n",
            "Episode 26300 Average Reward (last 100): -118.270\n",
            "Episode 26400 Average Reward (last 100): -117.860\n",
            "Episode 26500 Average Reward (last 100): -134.400\n",
            "Episode 26600 Average Reward (last 100): -107.200\n",
            "Episode 26700 Average Reward (last 100): -115.340\n",
            "Episode 26800 Average Reward (last 100): -113.930\n",
            "Episode 26900 Average Reward (last 100): -110.180\n",
            "Episode 27000 Average Reward (last 100): -117.800\n",
            "Episode 27100 Average Reward (last 100): -122.280\n",
            "Episode 27200 Average Reward (last 100): -111.680\n",
            "Episode 27300 Average Reward (last 100): -103.630\n",
            "Episode 27400 Average Reward (last 100): -111.850\n",
            "Episode 27500 Average Reward (last 100): -121.510\n",
            "Episode 27600 Average Reward (last 100): -107.630\n",
            "Episode 27700 Average Reward (last 100): -111.800\n",
            "Episode 27800 Average Reward (last 100): -105.490\n",
            "Episode 27900 Average Reward (last 100): -119.780\n",
            "Episode 28000 Average Reward (last 100): -117.780\n",
            "Episode 28100 Average Reward (last 100): -113.880\n",
            "Episode 28200 Average Reward (last 100): -117.890\n",
            "Episode 28300 Average Reward (last 100): -109.400\n",
            "Episode 28400 Average Reward (last 100): -122.110\n",
            "Episode 28500 Average Reward (last 100): -116.100\n",
            "Episode 28600 Average Reward (last 100): -103.450\n",
            "Episode 28700 Average Reward (last 100): -134.420\n",
            "Episode 28800 Average Reward (last 100): -122.050\n",
            "Episode 28900 Average Reward (last 100): -136.220\n",
            "Episode 29000 Average Reward (last 100): -111.740\n",
            "Episode 29100 Average Reward (last 100): -126.590\n",
            "Episode 29200 Average Reward (last 100): -126.100\n",
            "Episode 29300 Average Reward (last 100): -117.230\n",
            "Episode 29400 Average Reward (last 100): -127.920\n",
            "Episode 29500 Average Reward (last 100): -122.240\n",
            "Episode 29600 Average Reward (last 100): -107.610\n",
            "Episode 29700 Average Reward (last 100): -119.730\n",
            "Episode 29800 Average Reward (last 100): -111.330\n",
            "Episode 29900 Average Reward (last 100): -107.610\n",
            "Episode 30000 Average Reward (last 100): -109.790\n",
            "Episode 30100 Average Reward (last 100): -130.180\n",
            "Episode 30200 Average Reward (last 100): -115.680\n",
            "Episode 30300 Average Reward (last 100): -107.450\n",
            "Episode 30400 Average Reward (last 100): -126.100\n",
            "Episode 30500 Average Reward (last 100): -126.150\n",
            "Episode 30600 Average Reward (last 100): -117.900\n",
            "Episode 30700 Average Reward (last 100): -177.390\n",
            "Episode 30800 Average Reward (last 100): -131.510\n",
            "Episode 30900 Average Reward (last 100): -129.250\n",
            "Episode 31000 Average Reward (last 100): -137.440\n",
            "Episode 31100 Average Reward (last 100): -109.360\n",
            "Episode 31200 Average Reward (last 100): -174.010\n",
            "Episode 31300 Average Reward (last 100): -145.400\n",
            "Episode 31400 Average Reward (last 100): -103.640\n",
            "Episode 31500 Average Reward (last 100): -119.520\n",
            "Episode 31600 Average Reward (last 100): -117.340\n",
            "Episode 31700 Average Reward (last 100): -111.880\n",
            "Episode 31800 Average Reward (last 100): -134.550\n",
            "Episode 31900 Average Reward (last 100): -111.410\n",
            "Episode 32000 Average Reward (last 100): -101.020\n",
            "Episode 32100 Average Reward (last 100): -111.340\n",
            "Episode 32200 Average Reward (last 100): -109.320\n",
            "Episode 32300 Average Reward (last 100): -95.130\n",
            "Episode 32400 Average Reward (last 100): -109.380\n",
            "Episode 32500 Average Reward (last 100): -105.190\n",
            "Episode 32600 Average Reward (last 100): -107.500\n",
            "Episode 32700 Average Reward (last 100): -96.590\n",
            "Episode 32800 Average Reward (last 100): -94.560\n",
            "Episode 32900 Average Reward (last 100): -101.100\n",
            "Episode 33000 Average Reward (last 100): -102.470\n",
            "Episode 33100 Average Reward (last 100): -115.370\n",
            "Episode 33200 Average Reward (last 100): -109.620\n",
            "Episode 33300 Average Reward (last 100): -109.320\n",
            "Episode 33400 Average Reward (last 100): -111.810\n",
            "Episode 33500 Average Reward (last 100): -115.660\n",
            "Episode 33600 Average Reward (last 100): -98.810\n",
            "Episode 33700 Average Reward (last 100): -91.280\n",
            "Episode 33800 Average Reward (last 100): -107.560\n",
            "Episode 33900 Average Reward (last 100): -109.690\n",
            "Episode 34000 Average Reward (last 100): -101.300\n",
            "Episode 34100 Average Reward (last 100): -88.620\n",
            "Episode 34200 Average Reward (last 100): -103.520\n",
            "Episode 34300 Average Reward (last 100): -88.490\n",
            "Episode 34400 Average Reward (last 100): -103.070\n",
            "Episode 34500 Average Reward (last 100): -109.290\n",
            "Episode 34600 Average Reward (last 100): -101.580\n",
            "Episode 34700 Average Reward (last 100): -84.900\n",
            "Episode 34800 Average Reward (last 100): -88.210\n",
            "Episode 34900 Average Reward (last 100): -107.200\n",
            "Episode 35000 Average Reward (last 100): -91.110\n",
            "Episode 35100 Average Reward (last 100): -92.910\n",
            "Episode 35200 Average Reward (last 100): -96.890\n",
            "Episode 35300 Average Reward (last 100): -105.350\n",
            "Episode 35400 Average Reward (last 100): -90.730\n",
            "Episode 35500 Average Reward (last 100): -102.610\n",
            "Episode 35600 Average Reward (last 100): -92.520\n",
            "Episode 35700 Average Reward (last 100): -128.060\n",
            "Episode 35800 Average Reward (last 100): -95.050\n",
            "Episode 35900 Average Reward (last 100): -96.520\n",
            "Episode 36000 Average Reward (last 100): -105.470\n",
            "Episode 36100 Average Reward (last 100): -169.020\n",
            "Episode 36200 Average Reward (last 100): -107.300\n",
            "Episode 36300 Average Reward (last 100): -90.320\n",
            "Episode 36400 Average Reward (last 100): -95.130\n",
            "Episode 36500 Average Reward (last 100): -95.420\n",
            "Episode 36600 Average Reward (last 100): -103.380\n",
            "Episode 36700 Average Reward (last 100): -116.270\n",
            "Episode 36800 Average Reward (last 100): -96.440\n",
            "Episode 36900 Average Reward (last 100): -95.020\n",
            "Episode 37000 Average Reward (last 100): -87.020\n",
            "Episode 37100 Average Reward (last 100): -96.980\n",
            "Episode 37200 Average Reward (last 100): -75.980\n",
            "Episode 37300 Average Reward (last 100): -86.870\n",
            "Episode 37400 Average Reward (last 100): -101.460\n",
            "Episode 37500 Average Reward (last 100): -101.220\n",
            "Episode 37600 Average Reward (last 100): -144.960\n",
            "Episode 37700 Average Reward (last 100): -90.520\n",
            "Episode 37800 Average Reward (last 100): -146.560\n",
            "Episode 37900 Average Reward (last 100): -96.620\n",
            "Episode 38000 Average Reward (last 100): -95.650\n",
            "Episode 38100 Average Reward (last 100): -182.220\n",
            "Episode 38200 Average Reward (last 100): -131.130\n",
            "Episode 38300 Average Reward (last 100): -142.040\n",
            "Episode 38400 Average Reward (last 100): -88.990\n",
            "Episode 38500 Average Reward (last 100): -97.260\n",
            "Episode 38600 Average Reward (last 100): -103.210\n",
            "Episode 38700 Average Reward (last 100): -107.310\n",
            "Episode 38800 Average Reward (last 100): -156.730\n",
            "Episode 38900 Average Reward (last 100): -162.790\n",
            "Episode 39000 Average Reward (last 100): -155.780\n",
            "Episode 39100 Average Reward (last 100): -117.500\n",
            "Episode 39200 Average Reward (last 100): -95.080\n",
            "Episode 39300 Average Reward (last 100): -107.640\n",
            "Episode 39400 Average Reward (last 100): -105.440\n",
            "Episode 39500 Average Reward (last 100): -107.850\n",
            "Episode 39600 Average Reward (last 100): -143.950\n",
            "Episode 39700 Average Reward (last 100): -88.920\n",
            "Episode 39800 Average Reward (last 100): -97.140\n",
            "Episode 39900 Average Reward (last 100): -122.140\n",
            "Episode 40000 Average Reward (last 100): -95.020\n",
            "Episode 40100 Average Reward (last 100): -84.120\n",
            "Episode 40200 Average Reward (last 100): -92.910\n",
            "Episode 40300 Average Reward (last 100): -113.660\n",
            "Episode 40400 Average Reward (last 100): -111.460\n",
            "Episode 40500 Average Reward (last 100): -88.570\n",
            "Episode 40600 Average Reward (last 100): -104.960\n",
            "Episode 40700 Average Reward (last 100): -112.320\n",
            "Episode 40800 Average Reward (last 100): -145.980\n",
            "Episode 40900 Average Reward (last 100): -177.410\n",
            "Episode 41000 Average Reward (last 100): -88.990\n",
            "Episode 41100 Average Reward (last 100): -107.210\n",
            "Episode 41200 Average Reward (last 100): -86.520\n",
            "Episode 41300 Average Reward (last 100): -99.020\n",
            "Episode 41400 Average Reward (last 100): -107.200\n",
            "Episode 41500 Average Reward (last 100): -107.610\n",
            "Episode 41600 Average Reward (last 100): -105.520\n",
            "Episode 41700 Average Reward (last 100): -108.930\n",
            "Episode 41800 Average Reward (last 100): -103.230\n",
            "Episode 41900 Average Reward (last 100): -103.080\n",
            "Episode 42000 Average Reward (last 100): -93.240\n",
            "Episode 42100 Average Reward (last 100): -107.140\n",
            "Episode 42200 Average Reward (last 100): -96.730\n",
            "Episode 42300 Average Reward (last 100): -96.720\n",
            "Episode 42400 Average Reward (last 100): -99.370\n",
            "Episode 42500 Average Reward (last 100): -114.770\n",
            "Episode 42600 Average Reward (last 100): -99.160\n",
            "Episode 42700 Average Reward (last 100): -86.990\n",
            "Episode 42800 Average Reward (last 100): -113.530\n",
            "Episode 42900 Average Reward (last 100): -95.260\n",
            "Episode 43000 Average Reward (last 100): -113.570\n",
            "Episode 43100 Average Reward (last 100): -121.690\n",
            "Episode 43200 Average Reward (last 100): -92.950\n",
            "Episode 43300 Average Reward (last 100): -88.620\n",
            "Episode 43400 Average Reward (last 100): -110.870\n",
            "Episode 43500 Average Reward (last 100): -121.950\n",
            "Episode 43600 Average Reward (last 100): -117.420\n",
            "Episode 43700 Average Reward (last 100): -119.470\n",
            "Episode 43800 Average Reward (last 100): -90.950\n",
            "Episode 43900 Average Reward (last 100): -89.030\n",
            "Episode 44000 Average Reward (last 100): -88.700\n",
            "Episode 44100 Average Reward (last 100): -95.170\n",
            "Episode 44200 Average Reward (last 100): -99.530\n",
            "Episode 44300 Average Reward (last 100): -104.990\n",
            "Episode 44400 Average Reward (last 100): -90.800\n",
            "Episode 44500 Average Reward (last 100): -105.360\n",
            "Episode 44600 Average Reward (last 100): -111.200\n",
            "Episode 44700 Average Reward (last 100): -103.290\n",
            "Episode 44800 Average Reward (last 100): -95.160\n",
            "Episode 44900 Average Reward (last 100): -111.580\n",
            "Episode 45000 Average Reward (last 100): -94.680\n",
            "Episode 45100 Average Reward (last 100): -107.220\n",
            "Episode 45200 Average Reward (last 100): -105.270\n",
            "Episode 45300 Average Reward (last 100): -107.480\n",
            "Episode 45400 Average Reward (last 100): -103.450\n",
            "Episode 45500 Average Reward (last 100): -119.230\n",
            "Episode 45600 Average Reward (last 100): -70.330\n",
            "Episode 45700 Average Reward (last 100): -106.750\n",
            "Episode 45800 Average Reward (last 100): -109.180\n",
            "Episode 45900 Average Reward (last 100): -92.540\n",
            "Episode 46000 Average Reward (last 100): -103.240\n",
            "Episode 46100 Average Reward (last 100): -78.460\n",
            "Episode 46200 Average Reward (last 100): -92.540\n",
            "Episode 46300 Average Reward (last 100): -88.910\n",
            "Episode 46400 Average Reward (last 100): -84.830\n",
            "Episode 46500 Average Reward (last 100): -94.900\n",
            "Episode 46600 Average Reward (last 100): -92.560\n",
            "Episode 46700 Average Reward (last 100): -98.960\n",
            "Episode 46800 Average Reward (last 100): -102.820\n",
            "Episode 46900 Average Reward (last 100): -107.150\n",
            "Episode 47000 Average Reward (last 100): -103.710\n",
            "Episode 47100 Average Reward (last 100): -107.670\n",
            "Episode 47200 Average Reward (last 100): -105.190\n",
            "Episode 47300 Average Reward (last 100): -105.380\n",
            "Episode 47400 Average Reward (last 100): -118.010\n",
            "Episode 47500 Average Reward (last 100): -104.970\n",
            "Episode 47600 Average Reward (last 100): -111.420\n",
            "Episode 47700 Average Reward (last 100): -107.260\n",
            "Episode 47800 Average Reward (last 100): -105.490\n",
            "Episode 47900 Average Reward (last 100): -99.210\n",
            "Episode 48000 Average Reward (last 100): -105.020\n",
            "Episode 48100 Average Reward (last 100): -99.000\n",
            "Episode 48200 Average Reward (last 100): -99.040\n",
            "Episode 48300 Average Reward (last 100): -114.960\n",
            "Episode 48400 Average Reward (last 100): -121.580\n",
            "Episode 48500 Average Reward (last 100): -109.210\n",
            "Episode 48600 Average Reward (last 100): -111.490\n",
            "Episode 48700 Average Reward (last 100): -107.240\n",
            "Episode 48800 Average Reward (last 100): -80.090\n",
            "Episode 48900 Average Reward (last 100): -107.190\n",
            "Episode 49000 Average Reward (last 100): -84.950\n",
            "Episode 49100 Average Reward (last 100): -117.390\n",
            "Episode 49200 Average Reward (last 100): -100.730\n",
            "Episode 49300 Average Reward (last 100): -105.290\n",
            "Episode 49400 Average Reward (last 100): -101.050\n",
            "Episode 49500 Average Reward (last 100): -109.390\n",
            "Episode 49600 Average Reward (last 100): -103.170\n",
            "Episode 49700 Average Reward (last 100): -90.280\n",
            "Episode 49800 Average Reward (last 100): -99.440\n",
            "Episode 49900 Average Reward (last 100): -107.730\n",
            "Episode 50000 Average Reward (last 100): -83.140\n",
            "Episode 50100 Average Reward (last 100): -107.420\n",
            "Episode 50200 Average Reward (last 100): -87.180\n",
            "Episode 50300 Average Reward (last 100): -96.830\n",
            "Episode 50400 Average Reward (last 100): -100.890\n",
            "Episode 50500 Average Reward (last 100): -107.590\n",
            "Episode 50600 Average Reward (last 100): -103.230\n",
            "Episode 50700 Average Reward (last 100): -96.490\n",
            "Episode 50800 Average Reward (last 100): -92.950\n",
            "Episode 50900 Average Reward (last 100): -102.880\n",
            "Episode 51000 Average Reward (last 100): -93.150\n",
            "Episode 51100 Average Reward (last 100): -105.670\n",
            "Episode 51200 Average Reward (last 100): -117.360\n",
            "Episode 51300 Average Reward (last 100): -92.990\n",
            "Episode 51400 Average Reward (last 100): -115.670\n",
            "Episode 51500 Average Reward (last 100): -105.140\n",
            "Episode 51600 Average Reward (last 100): -91.300\n",
            "Episode 51700 Average Reward (last 100): -101.310\n",
            "Episode 51800 Average Reward (last 100): -96.700\n",
            "Episode 51900 Average Reward (last 100): -119.420\n",
            "Episode 52000 Average Reward (last 100): -101.210\n",
            "Episode 52100 Average Reward (last 100): -109.540\n",
            "Episode 52200 Average Reward (last 100): -107.180\n",
            "Episode 52300 Average Reward (last 100): -107.310\n",
            "Episode 52400 Average Reward (last 100): -99.690\n",
            "Episode 52500 Average Reward (last 100): -107.340\n",
            "Episode 52600 Average Reward (last 100): -107.440\n",
            "Episode 52700 Average Reward (last 100): -109.030\n",
            "Episode 52800 Average Reward (last 100): -98.980\n",
            "Episode 52900 Average Reward (last 100): -103.210\n",
            "Episode 53000 Average Reward (last 100): -93.130\n",
            "Episode 53100 Average Reward (last 100): -109.490\n",
            "Episode 53200 Average Reward (last 100): -101.060\n",
            "Episode 53300 Average Reward (last 100): -109.080\n",
            "Episode 53400 Average Reward (last 100): -97.170\n",
            "Episode 53500 Average Reward (last 100): -95.340\n",
            "Episode 53600 Average Reward (last 100): -105.260\n",
            "Episode 53700 Average Reward (last 100): -107.030\n",
            "Episode 53800 Average Reward (last 100): -107.450\n",
            "Episode 53900 Average Reward (last 100): -101.300\n",
            "Episode 54000 Average Reward (last 100): -101.090\n",
            "Episode 54100 Average Reward (last 100): -86.250\n",
            "Episode 54200 Average Reward (last 100): -101.200\n",
            "Episode 54300 Average Reward (last 100): -88.630\n",
            "Episode 54400 Average Reward (last 100): -111.670\n",
            "Episode 54500 Average Reward (last 100): -101.220\n",
            "Episode 54600 Average Reward (last 100): -111.470\n",
            "Episode 54700 Average Reward (last 100): -126.000\n",
            "Episode 54800 Average Reward (last 100): -104.910\n",
            "Episode 54900 Average Reward (last 100): -76.230\n",
            "Episode 55000 Average Reward (last 100): -131.500\n",
            "Episode 55100 Average Reward (last 100): -125.090\n",
            "Episode 55200 Average Reward (last 100): -110.980\n",
            "Episode 55300 Average Reward (last 100): -95.070\n",
            "Episode 55400 Average Reward (last 100): -109.430\n",
            "Episode 55500 Average Reward (last 100): -109.610\n",
            "Episode 55600 Average Reward (last 100): -78.510\n",
            "Episode 55700 Average Reward (last 100): -129.430\n",
            "Episode 55800 Average Reward (last 100): -119.670\n",
            "Episode 55900 Average Reward (last 100): -97.420\n",
            "Episode 56000 Average Reward (last 100): -93.130\n",
            "Episode 56100 Average Reward (last 100): -115.230\n",
            "Episode 56200 Average Reward (last 100): -99.430\n",
            "Episode 56300 Average Reward (last 100): -100.590\n",
            "Episode 56400 Average Reward (last 100): -101.340\n",
            "Episode 56500 Average Reward (last 100): -88.760\n",
            "Episode 56600 Average Reward (last 100): -106.150\n",
            "Episode 56700 Average Reward (last 100): -99.060\n",
            "Episode 56800 Average Reward (last 100): -107.450\n",
            "Episode 56900 Average Reward (last 100): -103.490\n",
            "Episode 57000 Average Reward (last 100): -100.980\n",
            "Episode 57100 Average Reward (last 100): -102.500\n",
            "Episode 57200 Average Reward (last 100): -113.290\n",
            "Episode 57300 Average Reward (last 100): -107.260\n",
            "Episode 57400 Average Reward (last 100): -96.970\n",
            "Episode 57500 Average Reward (last 100): -97.390\n",
            "Episode 57600 Average Reward (last 100): -107.480\n",
            "Episode 57700 Average Reward (last 100): -99.610\n",
            "Episode 57800 Average Reward (last 100): -103.150\n",
            "Episode 57900 Average Reward (last 100): -109.470\n",
            "Episode 58000 Average Reward (last 100): -99.030\n",
            "Episode 58100 Average Reward (last 100): -117.490\n",
            "Episode 58200 Average Reward (last 100): -99.390\n",
            "Episode 58300 Average Reward (last 100): -97.310\n",
            "Episode 58400 Average Reward (last 100): -115.910\n",
            "Episode 58500 Average Reward (last 100): -105.530\n",
            "Episode 58600 Average Reward (last 100): -101.630\n",
            "Episode 58700 Average Reward (last 100): -109.100\n",
            "Episode 58800 Average Reward (last 100): -103.440\n",
            "Episode 58900 Average Reward (last 100): -125.910\n",
            "Episode 59000 Average Reward (last 100): -97.150\n",
            "Episode 59100 Average Reward (last 100): -109.680\n",
            "Episode 59200 Average Reward (last 100): -98.990\n",
            "Episode 59300 Average Reward (last 100): -113.360\n",
            "Episode 59400 Average Reward (last 100): -113.700\n",
            "Episode 59500 Average Reward (last 100): -93.140\n",
            "Episode 59600 Average Reward (last 100): -97.020\n",
            "Episode 59700 Average Reward (last 100): -100.870\n",
            "Episode 59800 Average Reward (last 100): -104.980\n",
            "Episode 59900 Average Reward (last 100): -105.390\n",
            "Episode 60000 Average Reward (last 100): -113.240\n",
            "Episode 60100 Average Reward (last 100): -101.230\n",
            "Episode 60200 Average Reward (last 100): -104.890\n",
            "Episode 60300 Average Reward (last 100): -99.070\n",
            "Episode 60400 Average Reward (last 100): -94.780\n",
            "Episode 60500 Average Reward (last 100): -107.220\n",
            "Episode 60600 Average Reward (last 100): -117.730\n",
            "Episode 60700 Average Reward (last 100): -96.860\n",
            "Episode 60800 Average Reward (last 100): -111.580\n",
            "Episode 60900 Average Reward (last 100): -97.240\n",
            "Episode 61000 Average Reward (last 100): -95.350\n",
            "Episode 61100 Average Reward (last 100): -97.490\n",
            "Episode 61200 Average Reward (last 100): -98.990\n",
            "Episode 61300 Average Reward (last 100): -96.640\n",
            "Episode 61400 Average Reward (last 100): -98.750\n",
            "Episode 61500 Average Reward (last 100): -105.050\n",
            "Episode 61600 Average Reward (last 100): -80.290\n",
            "Episode 61700 Average Reward (last 100): -113.790\n",
            "Episode 61800 Average Reward (last 100): -101.200\n",
            "Episode 61900 Average Reward (last 100): -96.640\n",
            "Episode 62000 Average Reward (last 100): -105.190\n",
            "Episode 62100 Average Reward (last 100): -90.770\n",
            "Episode 62200 Average Reward (last 100): -117.960\n",
            "Episode 62300 Average Reward (last 100): -99.110\n",
            "Episode 62400 Average Reward (last 100): -106.850\n",
            "Episode 62500 Average Reward (last 100): -86.800\n",
            "Episode 62600 Average Reward (last 100): -100.900\n",
            "Episode 62700 Average Reward (last 100): -90.830\n",
            "Episode 62800 Average Reward (last 100): -115.330\n",
            "Episode 62900 Average Reward (last 100): -88.540\n",
            "Episode 63000 Average Reward (last 100): -109.720\n",
            "Episode 63100 Average Reward (last 100): -119.920\n",
            "Episode 63200 Average Reward (last 100): -111.050\n",
            "Episode 63300 Average Reward (last 100): -102.950\n",
            "Episode 63400 Average Reward (last 100): -94.900\n",
            "Episode 63500 Average Reward (last 100): -93.010\n",
            "Episode 63600 Average Reward (last 100): -113.440\n",
            "Episode 63700 Average Reward (last 100): -95.450\n",
            "Episode 63800 Average Reward (last 100): -94.850\n",
            "Episode 63900 Average Reward (last 100): -90.500\n",
            "Episode 64000 Average Reward (last 100): -99.090\n",
            "Episode 64100 Average Reward (last 100): -87.030\n",
            "Episode 64200 Average Reward (last 100): -87.300\n",
            "Episode 64300 Average Reward (last 100): -102.690\n",
            "Episode 64400 Average Reward (last 100): -97.090\n",
            "Episode 64500 Average Reward (last 100): -115.850\n",
            "Episode 64600 Average Reward (last 100): -107.090\n",
            "Episode 64700 Average Reward (last 100): -109.380\n",
            "Episode 64800 Average Reward (last 100): -104.960\n",
            "Episode 64900 Average Reward (last 100): -97.100\n",
            "Episode 65000 Average Reward (last 100): -106.720\n",
            "Episode 65100 Average Reward (last 100): -103.110\n",
            "Episode 65200 Average Reward (last 100): -94.930\n",
            "Episode 65300 Average Reward (last 100): -117.520\n",
            "Episode 65400 Average Reward (last 100): -107.410\n",
            "Episode 65500 Average Reward (last 100): -95.230\n",
            "Episode 65600 Average Reward (last 100): -113.430\n",
            "Episode 65700 Average Reward (last 100): -76.370\n",
            "Episode 65800 Average Reward (last 100): -93.360\n",
            "Episode 65900 Average Reward (last 100): -107.280\n",
            "Episode 66000 Average Reward (last 100): -86.780\n",
            "Episode 66100 Average Reward (last 100): -96.680\n",
            "Episode 66200 Average Reward (last 100): -103.680\n",
            "Episode 66300 Average Reward (last 100): -95.120\n",
            "Episode 66400 Average Reward (last 100): -111.770\n",
            "Episode 66500 Average Reward (last 100): -115.600\n",
            "Episode 66600 Average Reward (last 100): -97.030\n",
            "Episode 66700 Average Reward (last 100): -119.710\n",
            "Episode 66800 Average Reward (last 100): -102.660\n",
            "Episode 66900 Average Reward (last 100): -78.530\n",
            "Episode 67000 Average Reward (last 100): -96.980\n",
            "Episode 67100 Average Reward (last 100): -88.760\n",
            "Episode 67200 Average Reward (last 100): -119.510\n",
            "Episode 67300 Average Reward (last 100): -101.170\n",
            "Episode 67400 Average Reward (last 100): -98.750\n",
            "Episode 67500 Average Reward (last 100): -106.630\n",
            "Episode 67600 Average Reward (last 100): -85.100\n",
            "Episode 67700 Average Reward (last 100): -113.470\n",
            "Episode 67800 Average Reward (last 100): -107.520\n",
            "Episode 67900 Average Reward (last 100): -101.260\n",
            "Episode 68000 Average Reward (last 100): -98.660\n",
            "Episode 68100 Average Reward (last 100): -129.650\n",
            "Episode 68200 Average Reward (last 100): -109.210\n",
            "Episode 68300 Average Reward (last 100): -93.290\n",
            "Episode 68400 Average Reward (last 100): -101.400\n",
            "Episode 68500 Average Reward (last 100): -107.310\n",
            "Episode 68600 Average Reward (last 100): -87.210\n",
            "Episode 68700 Average Reward (last 100): -99.150\n",
            "Episode 68800 Average Reward (last 100): -102.680\n",
            "Episode 68900 Average Reward (last 100): -73.910\n",
            "Episode 69000 Average Reward (last 100): -105.500\n",
            "Episode 69100 Average Reward (last 100): -86.610\n",
            "Episode 69200 Average Reward (last 100): -113.130\n",
            "Episode 69300 Average Reward (last 100): -109.340\n",
            "Episode 69400 Average Reward (last 100): -126.210\n",
            "Episode 69500 Average Reward (last 100): -107.250\n",
            "Episode 69600 Average Reward (last 100): -84.360\n",
            "Episode 69700 Average Reward (last 100): -82.290\n",
            "Episode 69800 Average Reward (last 100): -86.480\n",
            "Episode 69900 Average Reward (last 100): -101.160\n",
            "Episode 70000 Average Reward (last 100): -109.200\n",
            "Episode 70100 Average Reward (last 100): -90.900\n",
            "Episode 70200 Average Reward (last 100): -105.530\n",
            "Episode 70300 Average Reward (last 100): -88.570\n",
            "Episode 70400 Average Reward (last 100): -105.190\n",
            "Episode 70500 Average Reward (last 100): -107.440\n",
            "Episode 70600 Average Reward (last 100): -92.470\n",
            "Episode 70700 Average Reward (last 100): -103.350\n",
            "Episode 70800 Average Reward (last 100): -101.440\n",
            "Episode 70900 Average Reward (last 100): -100.780\n",
            "Episode 71000 Average Reward (last 100): -95.320\n",
            "Episode 71100 Average Reward (last 100): -121.840\n",
            "Episode 71200 Average Reward (last 100): -78.720\n",
            "Episode 71300 Average Reward (last 100): -147.220\n",
            "Episode 71400 Average Reward (last 100): -92.950\n",
            "Episode 71500 Average Reward (last 100): -97.310\n",
            "Episode 71600 Average Reward (last 100): -121.600\n",
            "Episode 71700 Average Reward (last 100): -104.790\n",
            "Episode 71800 Average Reward (last 100): -92.720\n",
            "Episode 71900 Average Reward (last 100): -130.760\n",
            "Episode 72000 Average Reward (last 100): -84.820\n",
            "Episode 72100 Average Reward (last 100): -124.870\n",
            "Episode 72200 Average Reward (last 100): -133.620\n",
            "Episode 72300 Average Reward (last 100): -111.390\n",
            "Episode 72400 Average Reward (last 100): -103.160\n",
            "Episode 72500 Average Reward (last 100): -103.330\n",
            "Episode 72600 Average Reward (last 100): -107.380\n",
            "Episode 72700 Average Reward (last 100): -106.910\n",
            "Episode 72800 Average Reward (last 100): -99.370\n",
            "Episode 72900 Average Reward (last 100): -84.440\n",
            "Episode 73000 Average Reward (last 100): -128.050\n",
            "Episode 73100 Average Reward (last 100): -80.210\n",
            "Episode 73200 Average Reward (last 100): -84.700\n",
            "Episode 73300 Average Reward (last 100): -101.040\n",
            "Episode 73400 Average Reward (last 100): -111.450\n",
            "Episode 73500 Average Reward (last 100): -115.290\n",
            "Episode 73600 Average Reward (last 100): -84.130\n",
            "Episode 73700 Average Reward (last 100): -105.180\n",
            "Episode 73800 Average Reward (last 100): -96.860\n",
            "Episode 73900 Average Reward (last 100): -87.200\n",
            "Episode 74000 Average Reward (last 100): -88.810\n",
            "Episode 74100 Average Reward (last 100): -98.770\n",
            "Episode 74200 Average Reward (last 100): -103.220\n",
            "Episode 74300 Average Reward (last 100): -99.200\n",
            "Episode 74400 Average Reward (last 100): -107.060\n",
            "Episode 74500 Average Reward (last 100): -107.320\n",
            "Episode 74600 Average Reward (last 100): -74.580\n",
            "Episode 74700 Average Reward (last 100): -109.600\n",
            "Episode 74800 Average Reward (last 100): -86.560\n",
            "Episode 74900 Average Reward (last 100): -86.440\n",
            "Episode 75000 Average Reward (last 100): -105.560\n",
            "Episode 75100 Average Reward (last 100): -93.140\n",
            "Episode 75200 Average Reward (last 100): -103.480\n",
            "Episode 75300 Average Reward (last 100): -85.150\n",
            "Episode 75400 Average Reward (last 100): -111.520\n",
            "Episode 75500 Average Reward (last 100): -97.040\n",
            "Episode 75600 Average Reward (last 100): -97.190\n",
            "Episode 75700 Average Reward (last 100): -107.490\n",
            "Episode 75800 Average Reward (last 100): -97.000\n",
            "Episode 75900 Average Reward (last 100): -105.420\n",
            "Episode 76000 Average Reward (last 100): -100.610\n",
            "Episode 76100 Average Reward (last 100): -90.470\n",
            "Episode 76200 Average Reward (last 100): -103.470\n",
            "Episode 76300 Average Reward (last 100): -86.920\n",
            "Episode 76400 Average Reward (last 100): -102.960\n",
            "Episode 76500 Average Reward (last 100): -86.680\n",
            "Episode 76600 Average Reward (last 100): -111.230\n",
            "Episode 76700 Average Reward (last 100): -90.940\n",
            "Episode 76800 Average Reward (last 100): -103.210\n",
            "Episode 76900 Average Reward (last 100): -111.460\n",
            "Episode 77000 Average Reward (last 100): -80.460\n",
            "Episode 77100 Average Reward (last 100): -102.720\n",
            "Episode 77200 Average Reward (last 100): -107.400\n",
            "Episode 77300 Average Reward (last 100): -95.270\n",
            "Episode 77400 Average Reward (last 100): -97.700\n",
            "Episode 77500 Average Reward (last 100): -96.990\n",
            "Episode 77600 Average Reward (last 100): -107.570\n",
            "Episode 77700 Average Reward (last 100): -101.320\n",
            "Episode 77800 Average Reward (last 100): -92.330\n",
            "Episode 77900 Average Reward (last 100): -97.390\n",
            "Episode 78000 Average Reward (last 100): -102.640\n",
            "Episode 78100 Average Reward (last 100): -78.260\n",
            "Episode 78200 Average Reward (last 100): -92.860\n",
            "Episode 78300 Average Reward (last 100): -107.360\n",
            "Episode 78400 Average Reward (last 100): -105.570\n",
            "Episode 78500 Average Reward (last 100): -92.840\n",
            "Episode 78600 Average Reward (last 100): -80.180\n",
            "Episode 78700 Average Reward (last 100): -90.580\n",
            "Episode 78800 Average Reward (last 100): -109.210\n",
            "Episode 78900 Average Reward (last 100): -102.530\n",
            "Episode 79000 Average Reward (last 100): -103.630\n",
            "Episode 79100 Average Reward (last 100): -93.300\n",
            "Episode 79200 Average Reward (last 100): -103.600\n",
            "Episode 79300 Average Reward (last 100): -96.600\n",
            "Episode 79400 Average Reward (last 100): -94.810\n",
            "Episode 79500 Average Reward (last 100): -112.870\n",
            "Episode 79600 Average Reward (last 100): -94.660\n",
            "Episode 79700 Average Reward (last 100): -111.520\n",
            "Episode 79800 Average Reward (last 100): -111.490\n",
            "Episode 79900 Average Reward (last 100): -107.030\n",
            "Episode 80000 Average Reward (last 100): -107.670\n",
            "Episode 80100 Average Reward (last 100): -92.680\n",
            "Episode 80200 Average Reward (last 100): -103.140\n",
            "Episode 80300 Average Reward (last 100): -82.320\n",
            "Episode 80400 Average Reward (last 100): -94.860\n",
            "Episode 80500 Average Reward (last 100): -92.840\n",
            "Episode 80600 Average Reward (last 100): -107.470\n",
            "Episode 80700 Average Reward (last 100): -103.410\n",
            "Episode 80800 Average Reward (last 100): -76.330\n",
            "Episode 80900 Average Reward (last 100): -97.430\n",
            "Episode 81000 Average Reward (last 100): -101.430\n",
            "Episode 81100 Average Reward (last 100): -111.690\n",
            "Episode 81200 Average Reward (last 100): -119.500\n",
            "Episode 81300 Average Reward (last 100): -92.620\n",
            "Episode 81400 Average Reward (last 100): -91.100\n",
            "Episode 81500 Average Reward (last 100): -100.750\n",
            "Episode 81600 Average Reward (last 100): -113.690\n",
            "Episode 81700 Average Reward (last 100): -99.070\n",
            "Episode 81800 Average Reward (last 100): -107.480\n",
            "Episode 81900 Average Reward (last 100): -88.690\n",
            "Episode 82000 Average Reward (last 100): -96.850\n",
            "Episode 82100 Average Reward (last 100): -101.090\n",
            "Episode 82200 Average Reward (last 100): -107.650\n",
            "Episode 82300 Average Reward (last 100): -89.050\n",
            "Episode 82400 Average Reward (last 100): -103.570\n",
            "Episode 82500 Average Reward (last 100): -112.100\n",
            "Episode 82600 Average Reward (last 100): -95.410\n",
            "Episode 82700 Average Reward (last 100): -89.020\n",
            "Episode 82800 Average Reward (last 100): -95.210\n",
            "Episode 82900 Average Reward (last 100): -113.400\n",
            "Episode 83000 Average Reward (last 100): -100.740\n",
            "Episode 83100 Average Reward (last 100): -109.080\n",
            "Episode 83200 Average Reward (last 100): -105.300\n",
            "Episode 83300 Average Reward (last 100): -116.130\n",
            "Episode 83400 Average Reward (last 100): -113.470\n",
            "Episode 83500 Average Reward (last 100): -96.890\n",
            "Episode 83600 Average Reward (last 100): -103.110\n",
            "Episode 83700 Average Reward (last 100): -103.360\n",
            "Episode 83800 Average Reward (last 100): -87.020\n",
            "Episode 83900 Average Reward (last 100): -90.500\n",
            "Episode 84000 Average Reward (last 100): -90.430\n",
            "Episode 84100 Average Reward (last 100): -89.530\n",
            "Episode 84200 Average Reward (last 100): -104.820\n",
            "Episode 84300 Average Reward (last 100): -103.560\n",
            "Episode 84400 Average Reward (last 100): -123.970\n",
            "Episode 84500 Average Reward (last 100): -90.570\n",
            "Episode 84600 Average Reward (last 100): -88.970\n",
            "Episode 84700 Average Reward (last 100): -100.890\n",
            "Episode 84800 Average Reward (last 100): -101.210\n",
            "Episode 84900 Average Reward (last 100): -97.090\n",
            "Episode 85000 Average Reward (last 100): -93.540\n",
            "Episode 85100 Average Reward (last 100): -105.650\n",
            "Episode 85200 Average Reward (last 100): -86.920\n",
            "Episode 85300 Average Reward (last 100): -101.620\n",
            "Episode 85400 Average Reward (last 100): -99.150\n",
            "Episode 85500 Average Reward (last 100): -111.520\n",
            "Episode 85600 Average Reward (last 100): -107.500\n",
            "Episode 85700 Average Reward (last 100): -98.970\n",
            "Episode 85800 Average Reward (last 100): -113.300\n",
            "Episode 85900 Average Reward (last 100): -100.920\n",
            "Episode 86000 Average Reward (last 100): -94.670\n",
            "Episode 86100 Average Reward (last 100): -109.370\n",
            "Episode 86200 Average Reward (last 100): -107.270\n",
            "Episode 86300 Average Reward (last 100): -76.560\n",
            "Episode 86400 Average Reward (last 100): -103.210\n",
            "Episode 86500 Average Reward (last 100): -92.830\n",
            "Episode 86600 Average Reward (last 100): -98.990\n",
            "Episode 86700 Average Reward (last 100): -88.630\n",
            "Episode 86800 Average Reward (last 100): -107.330\n",
            "Episode 86900 Average Reward (last 100): -117.400\n",
            "Episode 87000 Average Reward (last 100): -92.390\n",
            "Episode 87100 Average Reward (last 100): -95.180\n",
            "Episode 87200 Average Reward (last 100): -98.640\n",
            "Episode 87300 Average Reward (last 100): -103.480\n",
            "Episode 87400 Average Reward (last 100): -96.980\n",
            "Episode 87500 Average Reward (last 100): -100.850\n",
            "Episode 87600 Average Reward (last 100): -90.700\n",
            "Episode 87700 Average Reward (last 100): -84.770\n",
            "Episode 87800 Average Reward (last 100): -101.450\n",
            "Episode 87900 Average Reward (last 100): -96.740\n",
            "Episode 88000 Average Reward (last 100): -92.550\n",
            "Episode 88100 Average Reward (last 100): -105.500\n",
            "Episode 88200 Average Reward (last 100): -87.200\n",
            "Episode 88300 Average Reward (last 100): -92.920\n",
            "Episode 88400 Average Reward (last 100): -111.420\n",
            "Episode 88500 Average Reward (last 100): -101.330\n",
            "Episode 88600 Average Reward (last 100): -115.930\n",
            "Episode 88700 Average Reward (last 100): -111.080\n",
            "Episode 88800 Average Reward (last 100): -101.810\n",
            "Episode 88900 Average Reward (last 100): -102.850\n",
            "Episode 89000 Average Reward (last 100): -90.560\n",
            "Episode 89100 Average Reward (last 100): -105.380\n",
            "Episode 89200 Average Reward (last 100): -107.330\n",
            "Episode 89300 Average Reward (last 100): -93.310\n",
            "Episode 89400 Average Reward (last 100): -96.860\n",
            "Episode 89500 Average Reward (last 100): -99.200\n",
            "Episode 89600 Average Reward (last 100): -97.690\n",
            "Episode 89700 Average Reward (last 100): -98.990\n",
            "Episode 89800 Average Reward (last 100): -101.030\n",
            "Episode 89900 Average Reward (last 100): -117.390\n",
            "Episode 90000 Average Reward (last 100): -89.030\n",
            "Episode 90100 Average Reward (last 100): -85.020\n",
            "Episode 90200 Average Reward (last 100): -106.870\n",
            "Episode 90300 Average Reward (last 100): -92.970\n",
            "Episode 90400 Average Reward (last 100): -109.070\n",
            "Episode 90500 Average Reward (last 100): -111.590\n",
            "Episode 90600 Average Reward (last 100): -105.560\n",
            "Episode 90700 Average Reward (last 100): -95.190\n",
            "Episode 90800 Average Reward (last 100): -105.460\n",
            "Episode 90900 Average Reward (last 100): -95.130\n",
            "Episode 91000 Average Reward (last 100): -105.720\n",
            "Episode 91100 Average Reward (last 100): -95.000\n",
            "Episode 91200 Average Reward (last 100): -105.060\n",
            "Episode 91300 Average Reward (last 100): -76.240\n",
            "Episode 91400 Average Reward (last 100): -101.070\n",
            "Episode 91500 Average Reward (last 100): -109.290\n",
            "Episode 91600 Average Reward (last 100): -103.090\n",
            "Episode 91700 Average Reward (last 100): -111.540\n",
            "Episode 91800 Average Reward (last 100): -109.340\n",
            "Episode 91900 Average Reward (last 100): -107.620\n",
            "Episode 92000 Average Reward (last 100): -109.490\n",
            "Episode 92100 Average Reward (last 100): -109.110\n",
            "Episode 92200 Average Reward (last 100): -86.470\n",
            "Episode 92300 Average Reward (last 100): -98.550\n",
            "Episode 92400 Average Reward (last 100): -103.300\n",
            "Episode 92500 Average Reward (last 100): -82.090\n",
            "Episode 92600 Average Reward (last 100): -105.440\n",
            "Episode 92700 Average Reward (last 100): -103.430\n",
            "Episode 92800 Average Reward (last 100): -105.220\n",
            "Episode 92900 Average Reward (last 100): -86.150\n",
            "Episode 93000 Average Reward (last 100): -92.950\n",
            "Episode 93100 Average Reward (last 100): -80.910\n",
            "Episode 93200 Average Reward (last 100): -97.250\n",
            "Episode 93300 Average Reward (last 100): -87.010\n",
            "Episode 93400 Average Reward (last 100): -112.960\n",
            "Episode 93500 Average Reward (last 100): -117.050\n",
            "Episode 93600 Average Reward (last 100): -99.270\n",
            "Episode 93700 Average Reward (last 100): -113.850\n",
            "Episode 93800 Average Reward (last 100): -111.750\n",
            "Episode 93900 Average Reward (last 100): -100.650\n",
            "Episode 94000 Average Reward (last 100): -103.620\n",
            "Episode 94100 Average Reward (last 100): -103.850\n",
            "Episode 94200 Average Reward (last 100): -96.700\n",
            "Episode 94300 Average Reward (last 100): -82.830\n",
            "Episode 94400 Average Reward (last 100): -94.830\n",
            "Episode 94500 Average Reward (last 100): -72.550\n",
            "Episode 94600 Average Reward (last 100): -101.750\n",
            "Episode 94700 Average Reward (last 100): -84.320\n",
            "Episode 94800 Average Reward (last 100): -100.480\n",
            "Episode 94900 Average Reward (last 100): -94.890\n",
            "Episode 95000 Average Reward (last 100): -107.720\n",
            "Episode 95100 Average Reward (last 100): -102.910\n",
            "Episode 95200 Average Reward (last 100): -84.280\n",
            "Episode 95300 Average Reward (last 100): -95.160\n",
            "Episode 95400 Average Reward (last 100): -101.490\n",
            "Episode 95500 Average Reward (last 100): -97.200\n",
            "Episode 95600 Average Reward (last 100): -97.000\n",
            "Episode 95700 Average Reward (last 100): -102.810\n",
            "Episode 95800 Average Reward (last 100): -115.690\n",
            "Episode 95900 Average Reward (last 100): -84.220\n",
            "Episode 96000 Average Reward (last 100): -97.480\n",
            "Episode 96100 Average Reward (last 100): -107.560\n",
            "Episode 96200 Average Reward (last 100): -90.450\n",
            "Episode 96300 Average Reward (last 100): -82.630\n",
            "Episode 96400 Average Reward (last 100): -98.450\n",
            "Episode 96500 Average Reward (last 100): -87.070\n",
            "Episode 96600 Average Reward (last 100): -94.940\n",
            "Episode 96700 Average Reward (last 100): -81.630\n",
            "Episode 96800 Average Reward (last 100): -88.840\n",
            "Episode 96900 Average Reward (last 100): -105.460\n",
            "Episode 97000 Average Reward (last 100): -80.980\n",
            "Episode 97100 Average Reward (last 100): -113.570\n",
            "Episode 97200 Average Reward (last 100): -101.190\n",
            "Episode 97300 Average Reward (last 100): -99.140\n",
            "Episode 97400 Average Reward (last 100): -107.490\n",
            "Episode 97500 Average Reward (last 100): -97.320\n",
            "Episode 97600 Average Reward (last 100): -88.830\n",
            "Episode 97700 Average Reward (last 100): -92.800\n",
            "Episode 97800 Average Reward (last 100): -90.950\n",
            "Episode 97900 Average Reward (last 100): -101.010\n",
            "Episode 98000 Average Reward (last 100): -86.620\n",
            "Episode 98100 Average Reward (last 100): -96.480\n",
            "Episode 98200 Average Reward (last 100): -121.700\n",
            "Episode 98300 Average Reward (last 100): -90.520\n",
            "Episode 98400 Average Reward (last 100): -95.330\n",
            "Episode 98500 Average Reward (last 100): -92.800\n",
            "Episode 98600 Average Reward (last 100): -109.120\n",
            "Episode 98700 Average Reward (last 100): -97.220\n",
            "Episode 98800 Average Reward (last 100): -99.350\n",
            "Episode 98900 Average Reward (last 100): -123.590\n",
            "Episode 99000 Average Reward (last 100): -90.350\n",
            "Episode 99100 Average Reward (last 100): -99.230\n",
            "Episode 99200 Average Reward (last 100): -106.930\n",
            "Episode 99300 Average Reward (last 100): -76.170\n",
            "Episode 99400 Average Reward (last 100): -102.980\n",
            "Episode 99500 Average Reward (last 100): -99.570\n",
            "Episode 99600 Average Reward (last 100): -96.750\n",
            "Episode 99700 Average Reward (last 100): -93.460\n",
            "Episode 99800 Average Reward (last 100): -97.240\n",
            "Episode 99900 Average Reward (last 100): -105.210\n",
            "Episode 100000 Average Reward (last 100): -101.330\n",
            "Últimos resultados: media = -127.8 , desvio padrao = 98.43759444439914\n",
            "Arquivo salvo: offPolicyD_weighted\n"
          ]
        }
      ],
      "source": [
        "if __name__ == \"__main__\":\n",
        "    r_max_plot = 10\n",
        "\n",
        "    EPISODES = 100000\n",
        "    LR = 0.01\n",
        "    GAMMA = 0.5723036890441425\n",
        "    EPSILON = 0.1915757619563071\n",
        "\n",
        "    \n",
        "    # Roda o algoritmo Monte-Carlo para o problema de controle (ou seja, para achar a política ótima)\n",
        "    rewards, Qtable = run_montecarloOffP_weighted(env, EPISODES, GAMMA, EPSILON, render=False)\n",
        "    print(\"Últimos resultados: media =\", np.mean(rewards[-20:]), \", desvio padrao =\", np.std(rewards[-20:]))\n",
        "\n",
        "    # Mostra um gráfico de episódios x retornos (não descontados)\n",
        "    # Se quiser salvar, passe o nome do arquivo no 3o parâmetro\n",
        "    filename = f\"results/montecarloOffP_weighted-{ENV_NAME.lower()[0:8]}-ep{EPISODES}.png\"\n",
        "    plot_result(rewards, r_max_plot,100, 'offPolicyD_weighted')\n",
        "\n",
        "    # test_greedy_Q_policy(env, Qtable, 10, True)\n",
        "    env.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1j8qwwqKP9mP"
      },
      "source": [
        "### Execução On-Policy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M6U2CoAOP9mP"
      },
      "source": [
        "#### Otimiza Parâmetros"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6wYzkdnvP9mP"
      },
      "outputs": [],
      "source": [
        "from numpy.random.mtrand import gamma\n",
        "\n",
        "import optuna\n",
        "\n",
        "\n",
        "\n",
        "ENV = gym.make(\"Taxi-v3\")\n",
        "\n",
        "\n",
        "# Esta função faz um treinamento com o Expected-SARSA, usando parâmetros sugeridos pelo Optuna.\n",
        "# Retorna a média dos retornos dos últimos 100 episódios.\n",
        "def train_values(trial : optuna.Trial):\n",
        "    \n",
        "    # chama os métodos do \"trial\" (tentativa) para sugerir valores para os parâmetros\n",
        "    lr = trial.suggest_uniform('learning_rate', 0.001, 1.0)\n",
        "    gamma = trial.suggest_uniform('gamma', 0.02, 1.0)\n",
        "    eps = trial.suggest_uniform('epsilon', 0.01, 0.2)\n",
        "   \n",
        "    \n",
        "    print(f\"\\nTRIAL #{trial.number}: eps={eps}, gamma={gamma}\")\n",
        "\n",
        "    # roda o algoritmo e recebe os retornos não-descontados\n",
        "    \n",
        "    (returns, _) = run_montecarloOnP(ENV, 20000, lr, gamma, eps, render=False)\n",
        "    return sum(returns[-100:])/100 "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jK5C5cAfP9mP",
        "outputId": "9b53579c-1b52-46ef-ac9d-c0f4a5467663"
      },
      "outputs": [],
      "source": [
        "study = optuna.create_study(direction='maximize', \n",
        "                            storage='sqlite:///optuna_studies.db', \n",
        "                            study_name= 'new_MC_onpolice', \n",
        "                            load_if_exists=True)\n",
        "study.optimize(train_values, n_trials=20) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JXQKv4x5P9mQ"
      },
      "source": [
        "#### Execução"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UcjKwJeKP9mQ",
        "outputId": "5c83fa0b-39e0-4f5f-f0c0-bb8f9cbb8aa2"
      },
      "outputs": [],
      "source": [
        "ENV_NAME = \"Taxi-v3\"  \n",
        "#ENV_NAME = \"MountainCarContinuous-v0\"  \n",
        "#ENV_NAME = \"LunarLander-v2\"  \n",
        "env = gym.make(ENV_NAME)\n",
        "\n",
        "#parameters: {'learning_rate': 0.007617314337157292, 'gamma': 0.8762195844017038, 'epsilon': 0.1594319424288697}. Best is trial 16 with value: -2.2.\n",
        "if __name__ == \"__main__\":\n",
        "    r_max_plot = 10\n",
        "\n",
        "    EPISODES = 100000\n",
        "    LR = 0.007617314337157292\n",
        "    GAMMA = 0.8762195844017038\n",
        "    EPSILON = 0.1594319424288697\n",
        "\n",
        "    \n",
        "    # Roda o algoritmo Monte-Carlo para o problema de controle (ou seja, para achar a política ótima)\n",
        "    rewards, Qtable = run_montecarloOnP(env, EPISODES, LR, GAMMA, EPSILON, render=False)\n",
        "    print(\"Últimos resultados: media =\", np.mean(rewards[-20:]), \", desvio padrao =\", np.std(rewards[-20:]))\n",
        "\n",
        "    # Mostra um gráfico de episódios x retornos (não descontados)\n",
        "    # Se quiser salvar, passe o nome do arquivo no 3o parâmetro\n",
        "    filename = f\"results/montecarloOnP-{ENV_NAME.lower()[0:8]}-ep{EPISODES}.png\"\n",
        "    plot_result(rewards, r_max_plot,100, 'onPolicyD')\n",
        "\n",
        "    # test_greedy_Q_policy(env, Qtable, 10, True)\n",
        "    env.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Lch6U12-WD3"
      },
      "source": [
        "## Contínuo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9kB46gwn-Yra"
      },
      "outputs": [],
      "source": [
        "\n",
        "ENV_NAME = \"MountainCar-v0\"  \n",
        "\n",
        "env = gym.make(ENV_NAME)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TEiYsqr3P9mU"
      },
      "outputs": [],
      "source": [
        "\n",
        "class GeneralDiscretizer:\n",
        "    def __init__(self, env, bins_per_dimension):\n",
        "        self.bins_per_dim = bins_per_dimension.copy()\n",
        "        self.intervals_per_dim = []\n",
        "        self.total_bins = 1\n",
        "        for i, bins in enumerate(bins_per_dimension):\n",
        "            self.intervals_per_dim.append(\n",
        "                np.linspace(env.observation_space.low[i], env.observation_space.high[i], bins+1) )\n",
        "            self.total_bins *= bins\n",
        "\n",
        "    def to_single_bin(self, state):\n",
        "        bin_vector = [(np.digitize(x=state[i], bins=intervals) - 1)\n",
        "                      for i, intervals in enumerate(self.intervals_per_dim)]\n",
        "        # print(bin_vector)\n",
        "        return self._bin_vector_to_single_bin(bin_vector, len(bin_vector)-1)\n",
        "\n",
        "    def _bin_vector_to_single_bin(self, vector, index):\n",
        "        if index < 0:\n",
        "            return 0\n",
        "        return vector[index] + self.bins_per_dim[index] * self._bin_vector_to_single_bin(vector, index-1)\n",
        "\n",
        "    def get_total_bins(self):\n",
        "        return self.total_bins\n",
        "\n",
        "\n",
        "class DiscreteObservationWrapper(gym.ObservationWrapper):\n",
        "    '''Classe para converter espaços contínuos em espaços discretos.\n",
        "    Esta classe converte ambientes de observações (estados) contínuos em ambientes de estados\n",
        "    discretos. Especificamente, ele converte representações dadas na forma de array de valores float\n",
        "    em um único inteiro $\\geq$ não-negativo (>=0).\n",
        "    \n",
        "    Precisa passar para o construtor uma lista que informa em quantos \"bins\" vai ser discretizada \n",
        "    cada dimensão (ou seja, cada valor float) do espaço de estados original.\n",
        "    '''\n",
        "    \n",
        "    def __init__(self, env, BINS_PER_DIMENSION):\n",
        "        super().__init__(env)\n",
        "        # cria um GeneralDiscretizer para converter um array de valores float em um único inteiro >= 0\n",
        "        # precisa dizer em quantos \"bins\" vai ser discretizada cada dimensão\n",
        "        self.discretizer = GeneralDiscretizer(env, BINS_PER_DIMENSION)\n",
        "        self.observation_space = gym.spaces.Discrete(self.discretizer.get_total_bins())\n",
        "\n",
        "    def observation(self, obs):\n",
        "        return self.discretizer.to_single_bin(obs)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "st7lYLp_P9mV"
      },
      "outputs": [],
      "source": [
        "from numpy.random.mtrand import gamma\n",
        "\n",
        "import optuna\n",
        "\n",
        "\n",
        "\n",
        "# Esta função faz um treinamento com o Expected-SARSA, usando parâmetros sugeridos pelo Optuna.\n",
        "# Retorna a média dos retornos dos últimos 100 episódios.\n",
        "def train_valuesOf(trial : optuna.Trial):\n",
        "    \n",
        "    # chama os métodos do \"trial\" (tentativa) para sugerir valores para os parâmetros\n",
        "    gamma = trial.suggest_uniform('gamma', 0.02, 1.0)\n",
        "    eps = trial.suggest_uniform('epsilon', 0.01, 0.2)\n",
        "    bins1 = trial.suggest_int('bins1', 5.0, 80.0)\n",
        "    bins2 = trial.suggest_int('bins2', 10.0, 90.0)\n",
        "    \n",
        "    \n",
        "    print(f\"\\nTRIAL #{trial.number}: eps={eps}, gamma={gamma}, bins1={bins1},bins2={bins2}\")\n",
        "\n",
        "    # roda o algoritmo e recebe os retornos não-descontados\n",
        "    env_wrapper = DiscreteObservationWrapper(env, [bins1,bins2])\n",
        "    (returns, _) = run_montecarloOffP(env_wrapper, 20000, gamma,eps, render=False)\n",
        "    return sum(returns[-100:])/100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HfPnGz-NP9mW"
      },
      "outputs": [],
      "source": [
        "def train_valuesOn(trial : optuna.Trial):\n",
        "    \n",
        "    # chama os métodos do \"trial\" (tentativa) para sugerir valores para os parâmetros\n",
        "    gamma = trial.suggest_uniform('gamma', 0.02, 1.0)\n",
        "    eps = trial.suggest_uniform('epsilon', 0.01, 0.2)\n",
        "    bins1 = trial.suggest_int('bins1', 5.0, 80.0)\n",
        "    bins2 = trial.suggest_int('bins2', 10.0, 90.0)\n",
        "   \n",
        "    \n",
        "    print(f\"\\nTRIAL #{trial.number}: eps={eps}, gamma={gamma}, bins1={bins1},bins2={bins2}\")\n",
        "\n",
        "    # roda o algoritmo e recebe os retornos não-descontados\n",
        "    env_wrapper = DiscreteObservationWrapper(env, [bins1,bins2])\n",
        "    (returns, _) = run_montecarloOffP(env_wrapper, 20000, gamma, eps, render=False)\n",
        "    return sum(returns[-100:])/100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "0MAejiOxP9mW",
        "outputId": "033aa398-d01a-416d-c698-0d75327ec4af"
      },
      "outputs": [],
      "source": [
        "study = optuna.create_study(direction='maximize', \n",
        "                            storage='sqlite:///optuna_studies.db', \n",
        "                            study_name= 'new_MC_offpolice_cont_bins_on-Policy', \n",
        "                            load_if_exists=True)\n",
        "\n",
        "\n",
        "study2 = optuna.create_study(direction='maximize', \n",
        "                            storage='sqlite:///optuna_studies.db', \n",
        "                            study_name= 'new_MC_offpolice_cont_bins_off-policy', \n",
        "                            load_if_exists=True)\n",
        "\n",
        "\n",
        "study.optimize(train_valuesOn, n_trials=30) \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3vZzK8JBKpim"
      },
      "outputs": [],
      "source": [
        "study2.optimize(train_valuesOf, n_trials=30)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Aio19xcn-cUA",
        "outputId": "19301a35-2801-4fae-ff3a-4e5828ec03a5"
      },
      "outputs": [],
      "source": [
        "if __name__ == \"__main__\":\n",
        "    r_max_plot = 10\n",
        "\n",
        "    EPISODES = 100000\n",
        "    GAMMA = 0.830525147061507\n",
        "    EPSILON = 0.05919712699520377\n",
        "\n",
        "    print(\"Ambiente Contínuo\")\n",
        "    # Roda o algoritmo Monte-Carlo para o problema de controle (ou seja, para achar a política ótima)\n",
        "    print(\"Monte-Carlo On-Policy\")\n",
        "    env_wrapper = DiscreteObservationWrapper(env, [70,70])\n",
        "    rewardsOn, QtableOn = run_montecarloOnP(env_wrapper, EPISODES, GAMMA, EPSILON, render=False)\n",
        "    print(\"Últimos resultados: media =\", np.mean(rewards[-20:]), \", desvio padrao =\", np.std(rewards[-20:]))\n",
        "    filename = f\"results/montecarloOnPolicyCont-{ENV_NAME.lower()[0:8]}-ep{EPISODES}.png\"\n",
        "    plot_result(rewards, r_max_plot,100, 'onPolicyC')\n",
        "\n",
        "    #test_greedy_Q_policy(env, QtableOn, 10, True)\n",
        "\n",
        "\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aCljnzSZcw4F",
        "outputId": "a917656d-eb94-42bd-ba1a-8eff48246f80"
      },
      "outputs": [],
      "source": [
        "    env_wrapper = DiscreteObservationWrapper(env, [70,70])\n",
        "    print(\"Monte-Carlo Off-Policy\")\n",
        "    env_wrapper = DiscreteObservationWrapper(env, [70,70])\n",
        "    rewardsOff, QtableOff = run_montecarloOffP(env_wrapper, EPISODES, GAMMA, EPSILON, render=False)\n",
        "    print(\"Últimos resultados: media =\", np.mean(rewards[-20:]), \", desvio padrao =\", np.std(rewards[-20:]))\n",
        "\n",
        "    # Mostra um gráfico de episódios x retornos (não descontados)\n",
        "    # Se quiser salvar, passe o nome do arquivo no 3o parâmetro\n",
        "    filename = f\"results/montecarloOffPolicyCont-{ENV_NAME.lower()[0:8]}-ep{EPISODES}.png\"\n",
        "    plot_result(rewards, r_max_plot,100, 'offPolicyC')\n",
        "\n",
        "    #test_greedy_Q_policy(env, QtableOff, 10, True)\n",
        "    env.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aH49RrTEawin"
      },
      "source": [
        "Continuo Ambiente 2 ()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aIZlQQ7t1OPH",
        "outputId": "2fa9ccae-f15e-4818-f7e2-b22fc186abf8"
      },
      "outputs": [],
      "source": [
        "!pip install gym[box2d]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xdYD8ayHdezv"
      },
      "outputs": [],
      "source": [
        "# ENV_NAME = \"CarRacing-v1\"  \n",
        "\n",
        "# env = gym.make(ENV_NAME)\n",
        "env = gym.make(\"Pendulum-v1\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a4aEhXCYfFuI"
      },
      "outputs": [],
      "source": [
        "def train_valuesOnCar(trial : optuna.Trial):\n",
        "    \n",
        "    # chama os métodos do \"trial\" (tentativa) para sugerir valores para os parâmetros\n",
        "    gamma = trial.suggest_uniform('gamma', 0.02, 1.0)\n",
        "    eps = trial.suggest_uniform('epsilon', 0.01, 0.2)\n",
        "    # bins1 = trial.suggest_int('bins1', -1, 1)\n",
        "    bins2 = trial.suggest_int('bins2', 5.0, 30.0)\n",
        "    bins3 = trial.suggest_int('bins3', 5.0, 10.0)\n",
        "   \n",
        "    \n",
        "    print(f\"\\nTRIAL #{trial.number}: eps={eps}, gamma={gamma},bins2={bins2},bins3={bins3}\")\n",
        "\n",
        "    # roda o algoritmo e recebe os retornos não-descontados\n",
        "    env_wrapper = DiscreteObservationWrapper(env, [bins2,bins3])\n",
        "    (returns, _) = run_montecarloOffP(env_wrapper, 2000, gamma, eps, render=False)\n",
        "    return sum(returns[-100:])/100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 643
        },
        "id": "LUiKZv05xFBe",
        "outputId": "09e26183-66bd-49ce-dc4c-a375cac5baca"
      },
      "outputs": [],
      "source": [
        "\n",
        "study = optuna.create_study(direction='maximize', \n",
        "                            storage='sqlite:///optuna_studies.db', \n",
        "                            study_name= 'new_MC_offpolice_cont_bins_off-policy', \n",
        "                            load_if_exists=True)\n",
        "\n",
        "study.optimize(train_valuesOnCar, n_trials=10) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "r_BcvZAi1zgv",
        "outputId": "51ddd1f3-fe97-4ac7-a64e-7c415deb7c32"
      },
      "outputs": [],
      "source": [
        "if __name__ == \"__main__\":\n",
        "    r_max_plot = 10\n",
        "\n",
        "    EPISODES = 100000\n",
        "    LR = 0.01\n",
        "    GAMMA = 0.830525147061507\n",
        "    EPSILON = 0.05919712699520377\n",
        " \n",
        "    #env_wrapper = DiscreteObservationWrapper(env, [1,80,90])\n",
        "\n",
        "    env = gym.make(\"FrozenLake-v1\")\n",
        "\n",
        "    \n",
        "    # Roda o algoritmo Monte-Carlo para o problema de controle (ou seja, para achar a política ótima)\n",
        "    rewards, Qtable = run_montecarloOffP(env, EPISODES, GAMMA, EPSILON, render=False)\n",
        "    print(\"Últimos resultados: media =\", np.mean(rewards[-20:]), \", desvio padrao =\", np.std(rewards[-20:]))\n",
        "\n",
        "    # Mostra um gráfico de episódios x retornos (não descontados)\n",
        "    # Se quiser salvar, passe o nome do arquivo no 3o parâmetro\n",
        "    filename = f\"results/montecarloOffPCar-{ENV_NAME.lower()[0:8]}-ep{EPISODES}.png\"\n",
        "    plot_result(rewards, r_max_plot,100, 'offPolicyC-CarRacing')\n",
        "\n",
        "    # test_greedy_Q_policy(env, Qtable, 10, True)\n",
        "    env.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rm18G8Wc5gZR",
        "outputId": "96ab212d-7193-4781-b591-922074b05e04"
      },
      "outputs": [],
      "source": [
        "rewards, Qtable = run_montecarloOnP(env, EPISODES, GAMMA, EPSILON, render=False)\n",
        "print(\"Últimos resultados: media =\", np.mean(rewards[-20:]), \", desvio padrao =\", np.std(rewards[-20:]))\n",
        "\n",
        "filename = f\"results/montecarloOffPCar-{ENV_NAME.lower()[0:8]}-ep{EPISODES}.png\"\n",
        "plot_result(rewards, r_max_plot,100, 'onPolicyC-CarRacing')\n",
        "\n",
        "   \n",
        "env.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jpp_6Bzk0rRC"
      },
      "source": [
        "# Plot Result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tExH-n_L0xjh"
      },
      "outputs": [],
      "source": [
        "def test_greedy_Q_policy(env, Q, num_episodes=100, render=False, render_wait=0.01, video=None):\n",
        "    \"\"\"\n",
        "    Avalia a política gulosa (greedy) definida implicitamente por uma Q-table.\n",
        "    Ou seja, executa, em todo estado s, a ação \"a = argmax Q(s,a)\".\n",
        "    - env: o ambiente\n",
        "    - Q: a Q-table (tabela Q) que será usada\n",
        "    - num_episodes: quantidade de episódios a serem executados\n",
        "    - render: defina como True se deseja chamar `env.render()` a cada passo\n",
        "    - render_wait: intervalo de tempo entre as chamadas a `env.render()`\n",
        "    - video \n",
        "    \n",
        "    Retorna:\n",
        "    - um par contendo o valor escalar do retorno médio por episódio e \n",
        "       a lista de retornos de todos os episódios\n",
        "    \"\"\"\n",
        "    episode_returns = []\n",
        "    total_steps = 0\n",
        "    for i in range(num_episodes):\n",
        "        print(f\"Episode {i+1}\")\n",
        "        obs = env.reset()\n",
        "        if render:\n",
        "            env.render()\n",
        "            time.sleep(render_wait)\n",
        "        if video is not None:\n",
        "            video.capture_frame()\n",
        "        done = False\n",
        "        episode_returns.append(0.0)\n",
        "        while not done:\n",
        "            action = np.argmax(Q[obs])\n",
        "            obs, reward, done, _ = env.step(action)\n",
        "            if render:\n",
        "                env.render()\n",
        "                time.sleep(render_wait)\n",
        "            if video is not None:\n",
        "                video.capture_frame()\n",
        "            total_steps += 1\n",
        "            episode_returns[-1] += reward\n",
        "        print(\"- retorno:\", episode_returns[-1])\n",
        "    mean_return = round(np.mean(episode_returns), 1)\n",
        "    print(\"Retorno médio (por episódio):\", mean_return, end=\"\")\n",
        "    print(\", episódios:\", len(episode_returns), end=\"\")\n",
        "    print(\", total de passos:\", total_steps)\n",
        "    show_state(env,total_steps)\n",
        "    if video is not None:\n",
        "        video.close()\n",
        "    return mean_return, episode_returns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2nrj0SU4096s"
      },
      "outputs": [],
      "source": [
        "def smooth(data, window):\n",
        "  data = np.array(data)\n",
        "  n = len(data)\n",
        "  y = np.zeros(n)\n",
        "  for i in range(n):\n",
        "    start = max(0, i-window+1)\n",
        "    y[i] = data[start:(i+1)].mean()\n",
        "  return y\n",
        "\n",
        "def plot_result(returns, ymax_suggested=None, window=100, filename=None):\n",
        "    '''Exibe um gráfico \"retornos x recompensas\", fazendo a média a cada 100 retornos, para suavizar.     \n",
        "    Se o parâmetro filename for fornecido, salva o gráfico em arquivo ao invés de exibir.\n",
        "    \n",
        "    Parâmetros:\n",
        "    - returns: lista de retornos a cada episódio\n",
        "    - ymax_suggested (opcional): valor máximo de retorno (eixo y), se tiver um valor máximo conhecido previamente\n",
        "    - filename: indique um nome de arquivo, se quiser salvar a imagem do gráfico; senão, o gráfico será apenas exibido\n",
        "    '''\n",
        "    plt.figure(figsize=(14,8))\n",
        "    smoothed_returns = smooth(returns, window)\n",
        "    xvalues = np.arange(1, len(returns)+1)\n",
        "    plt.plot(xvalues, smoothed_returns)\n",
        "    plt.xlabel('Episódios')\n",
        "    plt.ylabel('Retorno')\n",
        "    if ymax_suggested is not None:\n",
        "        ymax = np.max([ymax_suggested, np.max(smoothed_returns)])\n",
        "        plt.ylim(top=ymax)\n",
        "    plt.title(f\"Retorno médio a cada {window} episódios\")\n",
        "    if filename is None:\n",
        "        plt.show()\n",
        "    else:\n",
        "        plt.savefig(filename)\n",
        "        print(\"Arquivo salvo:\", filename)\n",
        "    plt.close()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lddRTK2LdWvI"
      },
      "source": [
        "# Exibe o ambiente"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DUY2uDh-P9mX"
      },
      "outputs": [],
      "source": [
        "from gym.wrappers.monitoring.video_recorder import VideoRecorder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lEJxnEr5kPkS"
      },
      "outputs": [],
      "source": [
        "ENV_NAME = 'MountainCar-v0'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HRspInThP9mX"
      },
      "outputs": [],
      "source": [
        "env = gym.make(ENV_NAME)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gktQMtqu_g7a"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "from IPython import display"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vai9dMYA_keu"
      },
      "outputs": [],
      "source": [
        "def show_state(env, step=0, info=\"\"):\n",
        "    plt.figure(3)\n",
        "    plt.clf()\n",
        "    plt.imshow(env.render(mode='rgb_array'))\n",
        "    plt.title(\"%s | Step: %d %s\" % (env._spec.id,step, info))\n",
        "    plt.axis('off')\n",
        "\n",
        "    display.clear_output(wait=True)\n",
        "    display.display(plt.gcf())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380
        },
        "id": "BMSFweJIsB9u",
        "outputId": "ad78e652-59f9-4606-c988-cb4a1e88958c"
      },
      "outputs": [],
      "source": [
        "#record_video(ENV_NAME, model, video_length=1000, prefix='monte-car-off-police')\n",
        "\n",
        "videoOf = VideoRecorder(env, \"monte-car-off-police.mp4\")\n",
        "#videoOn = VideoRecorder(env, \"monte-car-on-police.mp4\")\n",
        "#test_greedy_Q_policy(env, QtableOn, 10, True,videoOn)\n",
        "#render_mp4('video_offpolicy')\n",
        "\n",
        "test_greedy_Q_policy(env, QtableOn, 10, True,videoOf)\n",
        "render_mp4('monte-car-off-police.mp4')\n",
        "#show_videos('videos', prefix='monte-car-off-police')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "CwJjLOm-qo5x",
        "_Usxq5Z1qwbj",
        "pLlWktrRj9GZ"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.10.4 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    },
    "vscode": {
      "interpreter": {
        "hash": "de7c37f11048604427e696a7e966b00a255ebcd16cd0a44f6d549979884e8d96"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
